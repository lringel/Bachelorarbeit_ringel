{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Porto Seguro Notebook\n",
    "In diesem Notebook wird der Datensatz der brasilianischen Versicherungsfirma Porto Seguro aus einem Wettbewerb der Online-Community kaggle analysiert. Er ist unter dem folgenden Link erhältlich: <https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction/data?select=train.csv>\n",
    "Der Datensatz enthält Daten über Personen mit einer KfZ-Versicherung und soll dafür genutzt werden die Wahrscheinlichkeit eines Versicherungsfalles im Laufe des nächsten Jahres für eine bestimmte Person vorauszusagen. Von insgesamt 595.212 versicherten Personen im Trainingsdatensatz tritt bei 21.694 der Versicherungsfall im Laufe des Jahres ein. Der Datensatz weist damit ein hohes Ungleichgewicht auf, denn die Versicherungsfälle bilden im Trainingsdatensatz einen Anteil von etwa 3,645%. Ein Datenpunkt einer versicherten Person besteht aus 57 Attributen, einer `id` und der tatsächlichen Klasse `target`. Die `id` ist eine einzigartige Zuordnungsnummer, `target` die Zahl 0 oder 1. 0 steht für keinen Versicherungsfall im kommenden Jahr und 1 steht für einen Versicherungsfall im kommenden Jahr. Die 57 Attribute sind kontinuierlich, binär, nominal oder ordinal. Sie sind gekennzeichnet durch die Endungen `_bin` für binäre Attribute und `_cat` für kategorische Attribute. Die mittleren Namensteile der Daten geben weiteren Aufschluss über bestimmte Eigenschaften. `ind` bezieht sich auf die versicherte Person, `reg` bezieht sich auf eine Region, `car` bezieht sich auf das Auto und `calc` ist ein berechnetes Attribut. Attribute ohne eine Endung sind entweder ordinal oder kontinuierlich. Fehlende Werte bei Attributen sind als -1 gekennzeichnet.\n",
    "Das Notebook ist dabei in folgende Kapitel unterteilt:\n",
    "\n",
    "- **Initialisierung**: Einstellungen für nachfolgende Notebook Kapitel, Laden des Datensatzes und Verarbeitung fehlender Werte.\n",
    "- **Visualisierung**: Visualisierung der Verteilungen der einiger Attribute des Datensatzes.\n",
    "- **Analyse**:\n",
    "    - ***Training 1***: Aufspaltung des Datensatzes in Features und Labels. Transformation der Daten mit einem One-Hot-Encoder. Training verschiedener Algorithmen für das binäre Klassifikationsproblem.\n",
    "    - ***Klassierung 1***: Klassierung der Testdaten.\n",
    "    - ***Auswertung 1***: Auswertungen der Ergebnisse mittels verschiedener Bewertungskennzahlen und -methoden, welche sich aus der Konfusionsmatrix ableiten lassen.\n",
    "    - ***Datenmodifikation 2***: Modifikation der Daten durch Oversampling-Algorithmen.\n",
    "    - ***Training 2.1***: Training verschiedener Algorithmen mit durch Random Oversampling modifizierten Trainingsdaten für das binäre Klassifikationsproblem.\n",
    "    - ***Klassierung 2.1***: Klassierung der durch Random Oversampling modifizierten Testdaten.\n",
    "    - ***Auswertung 2.1***: Auswertungen der Ergebnisse mittels verschiedener Bewertungskennzahlen und -methoden, welche sich aus der Konfusionsmatrix ableiten lassen.\n",
    "    - ***Training 2.2.1***: Training verschiedener Algorithmen mit durch SMOTE (Rechteck) modifizierten Trainingsdaten für das binäre Klassifikationsproblem.\n",
    "    - ***Klassierung 2.2.1***: Klassierung der durch SMOTE (Rechteck) modifizierten Testdaten.\n",
    "    - ***Auswertung 2.2.1***: Auswertungen der Ergebnisse mittels verschiedener Bewertungskennzahlen und -methoden, welche sich aus der Konfusionsmatrix ableiten lassen.\n",
    "    - ***Training 2.2.2***: Training verschiedener Algorithmen mit durch SMOTE (Linie) modifizierten Trainingsdaten für das binäre Klassifikationsproblem.\n",
    "    - ***Klassierung 2.2.2***: Klassierung der durch SMOTE (Linie) modifizierten Testdaten.\n",
    "    - ***Auswertung 2.2.2***: Auswertungen der Ergebnisse mittels verschiedener Bewertungskennzahlen und -methoden, welche sich aus der Konfusionsmatrix ableiten lassen.\n",
    "    - ***Training 2.3***: Training verschiedener Algorithmen mit durch Borderline SMOTE modifizierten Trainingsdaten für das binäre Klassifikationsproblem.\n",
    "    - ***Klassierung 2.3***: Klassierung der durch Borderline SMOTE modifizierten Testdaten.\n",
    "    - ***Auswertung 2.3***: Auswertungen der Ergebnisse mittels verschiedener Bewertungskennzahlen und -methoden, welche sich aus der Konfusionsmatrix ableiten lassen.\n",
    "    - ***Training 2.4***: Training verschiedener Algorithmen mit durch ADASYN modifizierten Trainingsdaten für das binäre Klassifikationsproblem.\n",
    "    - ***Klassierung 2.4***: Klassierung der durch ADASYN modifizierten Testdaten.\n",
    "    - ***Auswertung 2.4***: Auswertungen der Ergebnisse mittels verschiedener Bewertungskennzahlen und -methoden, welche sich aus der Konfusionsmatrix ableiten lassen.\n",
    "    - ***Experimente***: Austesten von Kombinationen verschiedener Techniken zur Datenmodifikation.\n",
    "    - ***Datenmodifikation 3.1***: Der Trainingsdatensatz wird in vier gleich große Teile aufgespalten. Jeder der Teile wird von unterschiedlichen Oversampling-Algorithmen ausbalanciert. Nach Oversampling werden die vier Datensätze wieder zu einem einzigen zusammengefügt.\n",
    "    - ***Training 3.1***: Training verschiedener Algorithmen mit modifizierten Trainingsdaten für das binäre Klassifikationsproblem.\n",
    "    - ***Klassierung 3.1***: Klassierung der modifizierten Testdaten.\n",
    "    - ***Auswertung 3.1***: Auswertungen der Ergebnisse mittels verschiedener Bewertungskennzahlen und -methoden, welche sich aus der Konfusionsmatrix ableiten lassen.\n",
    "    - ***Datenmodifikation 3.2***: Der Trainingsdatensatz wird gestaffelt von vier verschiedenen Oversampling-Algorithmen ausbalanciert. Nach und nach wird ein Verhältnis von zuerst 1:4 bis hin zu 4:4 zwischen den zwei Klassen des binären Klassifikationsproblems hergestellt.\n",
    "    - ***Training 3.2***: Training verschiedener Algorithmen mit modifizierten Trainingsdaten für das binäre Klassifikationsproblem.\n",
    "    - ***Klassierung 3.2***: Klassierung der modifizierten Testdaten.\n",
    "    - ***Auswertung 3.2***: Auswertungen der Ergebnisse mittels verschiedener Bewertungskennzahlen und -methoden, welche sich aus der Konfusionsmatrix ableiten lassen.\n",
    "\n",
    "Für eine Interpretation der Ergebnisse seien Leser:innen auf die Bachelorarbeit verwiesen."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Initialisierung\n",
    "In diesem Kapitel werden Einstellungen für nachfolgende Kapitel des Notebooks vorgenommen, der mit Klassenzuordnungen versehene Datensatz `ps_train` (csv Datei) in einer Variable abgespeichert und fehlende Werte durch den Median aller Werte in deren zugehöriger Merkmalsausprägung ersetzt."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Importieren aller benötigten Module und Funktionen"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualisierung der Diagramme direkt im Notebook.\n",
    "%matplotlib inline\n",
    "# Importieren des Moduls matplotlib unter dem Namen mpl um Parameter für die Visualisierung festzulegen.\n",
    "import matplotlib as mpl\n",
    "# Importieren des Moduls matplotlib.pyplot zur Visualisierung.\n",
    "import matplotlib.pyplot as plt\n",
    "# Benötigte Importierungen der Module numpy und os.\n",
    "import numpy as np\n",
    "# Importieren des Moduls os um Zugriff auf das Festplattenverzeichnis zu erlangen.\n",
    "import os\n",
    "# Importieren der Funkion scatter_matrix aus dem Modul pandas.plotting zur Visualisierung von ccf_data in Streudiagrammen.\n",
    "from pandas.plotting import scatter_matrix\n",
    "# Importieren der Funktion train_test_split aus dem Modul sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Importieren des KNeighborsClassifier aus dem Modul sklearn.neighbors .\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Importieren der Funktion DecisionTreeClassifier aus dem Modul sklearn.tree .\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Importieren der Funktion RandomForestClassifier aus dem Modul sklearn.ensemble .\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Importieren der Funktion GaussianNB aus dem Modul sklearn.naive_bayes .\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Importieren von Seaborn zur Visualisierung der Konfusionsmatrix\n",
    "import seaborn as sns\n",
    "# Importieren der Funktionen roc_curve, roc_auc_score und precision_recall_curve, average_precision_score aus dem Modul sklearn.metrics zur Erstellung der ROC und PR Kurve sowie zur Berechnung des Flächeninhalts AUROC und dem gewichteten Mittelwert der Werte für precision an jedem Punkt der PR-Kurve.\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, average_precision_score\n",
    "# Importieren der Funktion confusion_matrix aus dem Modul sklearn.metrics .\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# Importieren des Moduls pandas um das Auslesen der csv Datei zu ermöglichen.\n",
    "import pandas as pd\n",
    "\n",
    "# Importierungen zur Transformation des Datensatzes\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, QuantileTransformer\n",
    "\n",
    "# Importieren der Funktionen RandomOverSampler, SMOTE, BorderlineSMOTE und ADASYN aus dem Modul imblearn.oversampling\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, BorderlineSMOTE, ADASYN\n",
    "# Importieren des Moduls pySMOTE für SMOTE mit der Interpolationsvariante Rechteck\n",
    "import pySMOTE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In diesem Abschnitt werden verschiedene Funktionen für die nachfolgenden Notebook Abschnitte definiert."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Funktion zur Abspeicherung von Bildern.\n",
    "# fig_id legt den Namen des abgespeicherten Bildes fest.\n",
    "# tight_layout passt automatisch die Größe mehrerer untergeordneter Graphen an, damit diese sich nicht überschneiden.\n",
    "# fig_extension legt den Datentyp des abgespeicherten Bildes fest.\n",
    "# resolution bestimmt die Auflösung des Bildes.\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Die Zelle definiert eine Funktion, um das Abspeichern einer csv Dateien zu ermöglichen."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Abspeichern des Pfades, unter welchem der Datensatz des Wettbewerbs abgespeichert ist.\n",
    "PS_PATH = os.path.join(\"datasets\", \"ps\")\n",
    "\n",
    "# Definition der Funktion load_ps_data.\n",
    "def load_ps_data(ccf_path=PS_PATH):\n",
    "    # Abspeichern des Pfades, unter welchem der Datensatz ps_test abgespeichert ist, in der Variable csv_path.\n",
    "    csv_path = os.path.join(ccf_path, \"ps_train.csv\")\n",
    "    # Auslesen der Daten in der csv Datei mit Hilfe von pandas. Abspeicherung in der Variablen data.\n",
    "    # Merkmalsausprägungen, welche in dem Datensatz fehlen, wurden durch den Wert -1 ersetzt. Diese Stellen werden im Folgenden durch den Ausdruck NaN (Not a Number) ausgetauscht.\n",
    "    data = pd.read_csv(csv_path, na_values='-1')\n",
    "    # Die fehlende Werte, welche nun durch NaN gekennzeichnet sind, werden durch den Median in ihrer Attributsspalte ausgetauscht.\n",
    "    data.fillna(value=data.median(), inplace=True)\n",
    "    # Rückgabe des vollständigen Datensatzes.\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Funktion um sechs verschiedene Klassifikatoren zu initialisieren. Für diese Funktionen werden Standardparameter definiert, wie beispielsweise 'neighbors' , 'estimators' und 'leafs', welche die Klassifikatoren individuell beeinflussen. Diese können abgeändert werden, sofern eine Umstellung der Klassifikatoren erwünscht ist."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Funktion welche eine Liste von initialisierten Klassifikatoren zurückgibt\n",
    "def create_classifiers(include_knn=True, neighbors=5, jobs=-1, random=42, estimators=10, leafs=16, alph=1, iter=1000):\n",
    "    classifier_list= [# Initialisieren des KNeighborsClassifier.\n",
    "                      # n_neighbors=5 bedeutet, dass für die Klassierung eines Punktes die Information von 5 Nachbarn beachtet wird.\n",
    "                      # n_jobs=-1 bedeutet, dass für die Berechnungen alle Kerne des CPU genutzt werden (-> schneller).\n",
    "                      KNeighborsClassifier(n_neighbors=neighbors, n_jobs=jobs),\n",
    "                      # Initialisieren des DecisionTreeClassifier mit dem Blatt-Aufspaltungskriterium 'gini' und dem random_state=42 um reproduzierbare Ergebnisse zu ermöglichen.\n",
    "                      DecisionTreeClassifier(criterion='gini', random_state=random),\n",
    "                      # Initialisieren des DecisionTreeClassifier mit dem Blatt-Aufspaltungskriterium 'entropy' und dem random_state=42 um reproduzierbare Ergebnisse zu ermöglichen.\n",
    "                      DecisionTreeClassifier(criterion='entropy', random_state=random),\n",
    "                      # Initialisieren eines RandomForestClassifier.\n",
    "                      # n_estimators=10 bedeutet, dass 10 Bäume erzeugt werden, welche das Voting übernehmen.\n",
    "                      # max_leaf_nodes=16 bedeutet, dass ein einzelner Baum der erzeugt wird, maximal 16 Blattknoten besitzen darf.\n",
    "                      # Festlegen des random_state auf 42 damit das Ergebnis reproduzierbar bleibt.\n",
    "                      # n_jobs=-1 bedeutet, dass für die Berechnungen alle Kerne des CPU genutzt werden (-> schneller).\n",
    "                      # criterion='entropy' legt Gini als Kriterium zur Aufspaltung der Knoten in den Entscheidungsbäumen fest.\n",
    "                      RandomForestClassifier(n_estimators=estimators, max_leaf_nodes=leafs, random_state=random, n_jobs=jobs, criterion='gini'),\n",
    "                      # Initialisieren eines RandomForestClassifier.\n",
    "                      # n_estimators=10 bedeutet, dass 10 Bäume erzeugt werden, welche das Voting übernehmen.\n",
    "                      # max_leaf_nodes=16 bedeutet dass ein einzelner Baum der erzeugt wird, maximal 16 Blattknoten besitzen darf.\n",
    "                      # Festlegen des random_state auf 42 damit das Ergebnis reproduzierbar bleibt.\n",
    "                      # n_jobs=-1 bedeutet, dass für die Berechnungen alle Kerne des CPU genutzt werden (-> schneller).\n",
    "                      # criterion='entropy' legt die Entropie als Kriterium zur Aufspaltung der Knoten in den Entscheidungsbäumen fest.\n",
    "                      RandomForestClassifier(n_estimators=estimators, max_leaf_nodes=leafs, random_state=random, n_jobs=jobs, criterion='entropy'),\n",
    "                      # Initialisieren eines Gaussian Naive Bayes.\n",
    "                      GaussianNB()]\n",
    "    # Rückgabe der Liste an Klassifikatoren\n",
    "    return classifier_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Funktion, um die in einer Liste abgespeicherten Klassifikatoren mit einem Trainingsdatensatz (bestehend aus den Attributsausprägungen 'train_features' und den Klassenzuordnungen 'train_labels') zu trainieren."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Funktion zum Trainieren von Klassifikatoren mit Trainingsdaten.\n",
    "# Die Trainingsdaten bestehen dabei aus den Features train_features und den Klassenzuordnungen train_labels.\n",
    "# In classifier_list sind die am Training teilnehmenden Klassifikatoren abgespeichert.\n",
    "def train_models(train_features, train_labels, classifier_list):\n",
    "    # Iterieren über die Liste der am Training teilnehmenden Klassifikatoren\n",
    "    for classifier in classifier_list:\n",
    "        # Training des aktuell ausgewählten Klassifikators mit den Trainingsdaten train_features und train_labels\n",
    "        classifier.fit(train_features, train_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Funktion um mit den trainierten Klassifikatoren einen Testdatensatz zu klassieren. Die Funktion gibt sowohl eindeutige Zuordnungen ('predictions'), als auch Wahrscheinlichkeiten für die Zuordnung zu einer Klasse ('prediction_probas') zurück."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Funktion zur Klassierung von Testdaten durch verschiedene Klassifikatoren.\n",
    "def klassieren(test_features, classifier_list):\n",
    "    # Anlegen zweier Listen. predictions speichert dabei die Klassierungen der Klassifikatoren aus der classifier_list ab. prediction_probas speichert die Wahrscheinlichkeiten für eine Klassenzugehörigkeit ab, welche die Klassifikatoren aus der classifier_list für einen Datenpunkt aus den Testdaten berechnet haben.\n",
    "    predictions=[]\n",
    "    prediction_probas=[]\n",
    "    # Iterieren über die Klassifikatoren aus der classifier_list.\n",
    "    for classifier in classifier_list:\n",
    "        # Klassierung der Testdaten.\n",
    "        predictions.append(classifier.predict(test_features))\n",
    "        # Berechnung der Wahrscheinlichkeit für eine Klassenzuordnung.\n",
    "        prediction_probas.append((classifier.predict_proba(test_features)))\n",
    "    # Rückgabe der Klassierungen und Wahrscheinlichkeiten für eine Klassenzuordnung.\n",
    "    return predictions, prediction_probas"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Funktion zur Erstellung einer Konfusionsmatrix. Diese wurde übernommen aus dem folgenden GitHub repository: <https://github.com/DTrimarchi10/confusion_matrix/blob/master/cf_matrix.py>\n",
    "Um die Ausgabe der Matrix mit der Verwendung in der Bachelorarbeit konsistent zu halten, wurden die Klassen 0 und 1 vertauscht. Zudem wurden die TN-Rate als Bewertungskennzahl hinzugefügt, die Größe der Abbildung abgeändert, zwei Parameter der Funktion abgeändert und die Kommentare auf Deutsch übersetzt."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def make_confusion_matrix(cf,\n",
    "                          group_names=None,\n",
    "                          count=True,\n",
    "                          percent=True,\n",
    "                          cbar=True,\n",
    "                          xyticks=True,\n",
    "                          xyplotlabels=True,\n",
    "                          sum_stats=True,\n",
    "                          figsize=None,\n",
    "                          cmap='Blues',\n",
    "                          title=None):\n",
    "    '''\n",
    "    This function will make a pretty plot of an sklearn Confusion Matrix cm using a Seaborn heatmap visualization.  #####Deutsch: Diese Funktion erzeugt eine schöne grafische Darstellung einer sklearn Konfusionsmatrix mit der Hilfe der Seaborn-Heatmap.\n",
    "    Arguments                                                                                                       #####Deutsch: Parameter\n",
    "    ---------\n",
    "    cf:            confusion matrix to be passed in                                                                 #####Deutsch: Konfusionsmatrix, die übergeben werden muss.\n",
    "    group_names:   List of strings that represent the labels row by row to be shown in each square.                 #####Deutsch: Liste von Elementen des Datentyps String, welche die Klassenzuordnungen Zeile für Zeile repräsentieren, die in der Matrix angezeigt                                                                                                                               werden sollen.\n",
    "    categories:    List of strings containing the categories to be displayed on the x,y axis. Default is 'auto'     #####Deutsch: Liste von Elementen des Datentyps String, welche die Kategorien enthält, die auf der x- und der y-Achse angezeigt werden sollen.\n",
    "    count:         If True, show the raw number in the confusion matrix. Default is True.                           #####Deutsch: Falls True, wird die absolute Häufigkeit in den Feldern der Konfusionsmatrix angezeigt. Die Standardeinstellung ist True.\n",
    "    percent:       If True, show the proportions for each category. Default is True.                                #####Deutsch: Falls True, werden die relativen Häufigkeiten der vier Kategorien im Verhältnis zum gesamten Datensatz angezeigt. Die                                                                                                                                             Standardeinstellung ist True.\n",
    "    cbar:          If True, show the color bar. The cbar values are based off the values in the confusion matrix.   #####Deutsch: Falls True, wird eine Farblegende für den Farbverlauf der einzelnen Felder angezeigt. Die Standardeinstellung ist True.\n",
    "                   Default is True.\n",
    "    xyticks:       If True, show x and y ticks. Default is True.                                                    #####Deutsch: Falls True, werden die Felder der Heatmap mit den Klassenzugehörigkeiten beschriftet. Die Standardeinstellung ist True.\n",
    "    xyplotlabels:  If True, show 'True Label' and 'Predicted Label' on the figure. Default is True.                 #####Deutsch: Falls True, werden die übergeordneten Beschriftungen 'Tatsächliche Klassenzuordnung' und 'Vorhergesagte Klassenzuordnung' angezeigt.                                                                                                                              Die Standardeinstellung ist True.\n",
    "    sum_stats:     If True, display summary statistics below the figure. Default is True.                           #####Deutsch: Falls True, werden unter der Heatmap einige Bewertungskennzahlen angezeigt. Die Standardeinstellung ist True.\n",
    "    figsize:       Tuple representing the figure size. Default will be the matplotlib rcParams value.               #####Deutsch: Tupel, welches die Abbildungsgröße festlegt. Die Standardeinstellungen sind die matplotlib rcParams Werte.\n",
    "    cmap:          Colormap of the values displayed from matplotlib.pyplot.cm. Default is 'Blues'                   #####Deutsch: Farbzuordnung der Werte die von matplotlib.pyplot.cm. angezeigt werden. Die Standardeinstellung ist 'Blues' (deutsch: Blautöne).\n",
    "                   See http://matplotlib.org/examples/color/colormaps_reference.html                                              Referenz zur matplotlib colormap: http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "\n",
    "    title:         Title for the heatmap. Default is None.                                                          #####Deutsch: Titel der Heatmap. Standardmäßig gibt es keinen Titel.\n",
    "    '''\n",
    "\n",
    "    # Vertauschen der Klassen für die Konsistenz der Konfusionsmatrix mit der restlichen Bachelorarbeit\n",
    "    e00 = cf[0][0]\n",
    "    e01 = cf[0][1]\n",
    "    e10 = cf[1][0]\n",
    "    e11 = cf[1][1]\n",
    "\n",
    "    cf[0][0] = e11\n",
    "    cf[1][1] = e00\n",
    "    cf[0][1] = e10\n",
    "    cf[1][0] = e01\n",
    "\n",
    "    # CODE TO GENERATE TEXT INSIDE EACH SQUARE                                                                      #####Deutsch: Source Code, um Text in jedem Feld zu erzeugen\n",
    "    blanks = ['' for i in range(cf.size)]\n",
    "\n",
    "    if group_names and len(group_names)==cf.size:\n",
    "        group_labels = [\"{}\\n\".format(value) for value in group_names]\n",
    "    else:\n",
    "        group_labels = blanks\n",
    "\n",
    "    if count:\n",
    "        group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\n",
    "    else:\n",
    "        group_counts = blanks\n",
    "\n",
    "    if percent:\n",
    "        group_percentages = [\"{0:.2%}\".format(value) for value in cf.flatten()/np.sum(cf)]\n",
    "    else:\n",
    "        group_percentages = blanks\n",
    "\n",
    "    box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels,group_counts,group_percentages)]\n",
    "    box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])\n",
    "\n",
    "\n",
    "    # CODE TO GENERATE SUMMARY STATISTICS & TEXT FOR SUMMARY STATS                                                  #####Deutsch: Source Code, um Bewertungskennzahlen und Text dazu anzuzeigen\n",
    "    if sum_stats:\n",
    "        #Accuracy is sum of diagonal divided by total observations                                                  #####Deutsch: Die Accuracy ist die Summe der Diagonale, geteilt durch die gesamte Zahl an Datenpunkten die klassiert wurden\n",
    "        accuracy  = np.trace(cf) / float(np.sum(cf))\n",
    "\n",
    "        #if it is a binary confusion matrix, show some more stats                                                   #####Deutsch: Sofern es eine binäre Konfusionsmatrix ist, werden weitere Bewertungskennzahlen angezeigt\n",
    "        if len(cf)==2:\n",
    "            #Metrics for Binary Confusion Matrices                                                                  #####Deutsch: Bewertungskennzahlen für binäre Konfusionsmatrizen\n",
    "            precision = cf[0,0] / sum(cf[:,0])\n",
    "            recall    = cf[0,0] / sum(cf[0,:])\n",
    "            f1_score  = 2*precision*recall / (precision + recall)\n",
    "            tn_rate   = cf[1,1] / sum(cf[1,:])\n",
    "            stats_text = \"\\n\\nAccuracy={:0.3f}\\nPrecision={:0.3f}\\nTP-Rate/Recall={:0.3f}\\nTN-Rate={:0.3f}\\nF1 Score={:0.3f}\".format(\n",
    "                accuracy,precision,recall,tn_rate,f1_score)\n",
    "        else:\n",
    "            stats_text = \"\\n\\nAccuracy={:0.3f}\".format(accuracy)\n",
    "    else:\n",
    "        stats_text = \"\"\n",
    "\n",
    "\n",
    "    # SET FIGURE PARAMETERS ACCORDING TO OTHER ARGUMENTS                                                            #####Deutsch: Parameter der Abbildung gemäß den übergebenen Parametern einstellen\n",
    "    if figsize==None:\n",
    "        #Get default figure size if not set                                                                         #####Deutsch: Sofern keine Abbildungsgröße angegeben wurde, wird die Standardgröße verwendet\n",
    "        figsize = plt.rcParams.get('figure.figsize')\n",
    "\n",
    "    if xyticks==False:\n",
    "        #Do not show categories if xyticks is False                                                                 #####Deutsch: Die Matrix wird nicht mit den Klassenzugehörigkeiten beschriftet\n",
    "        categories=False\n",
    "\n",
    "\n",
    "    # MAKE THE HEATMAP VISUALIZATION                                                                                #####Deutsch: Visualisierung der Heatmap\n",
    "    plt.figure(figsize=(1.5,1.5))\n",
    "    sns.heatmap(cf,annot=box_labels,fmt=\"\",cmap=cmap,cbar=cbar,xticklabels=[1, 0],yticklabels=[1, 0])\n",
    "\n",
    "    if xyplotlabels:\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label' + stats_text)\n",
    "    else:\n",
    "        plt.xlabel(stats_text)\n",
    "\n",
    "    if title:\n",
    "        plt.title(title)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Funktion zur Auswertung der trainierten Klassifikatoren mit dem Testdatensatz."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Funktion zur Auswertung der Klassierungen und berechneten Wahrscheinlichkeiten für eine Klassenzuordnung.\n",
    "def auswerten(predictions, prediction_probas, identifier):\n",
    "\n",
    "    # Liste von Klassifikatoren, um die Graphen des Algorithmus beschriften zu können.\n",
    "    classifiers = ['K-Nearest-Neighbors', 'Decision_Tree_Gini', 'Decision_Tree_Entropy', 'Random_Forest_Gini', 'Random_Forest_Entropy', 'Gaussian_Naive_Bayes']\n",
    "\n",
    "\n",
    "    # Initialisierung eines Zählers classifier_counter um zusätzlich über die Namen aus der Liste classifier iterieren zu können.\n",
    "    classifier_counter = 0\n",
    "\n",
    "\n",
    "    # Iterieren über alle Klassierungen in der Liste predictions.\n",
    "    for prediction in predictions:\n",
    "\n",
    "        # Anzeigen der Konfusionsmatrix.\n",
    "        # Zeilen = tatsächliche Kategorien.\n",
    "        # Spalten = vorhergesagte Kategorien.\n",
    "        #ConfusionMatrixDisplay.from_predictions(ps_test_labels, prediction)\n",
    "        cf_matrix = confusion_matrix(ps_test_labels, prediction)\n",
    "        make_confusion_matrix(cf_matrix, figsize=(2,2), cbar=False, percent=False) # Bei Bedarf kann hier die Konfusionsmatrix mit dem Namen des Klassifikators beschriftet werden. Source Code: , title=classifiers[classifier_counter]\n",
    "\n",
    "        # Einstellung der Schriftgröße\n",
    "        sns.set(font_scale=.5)\n",
    "\n",
    "        # Erzeugung eines Namens für die Konfusionsmatrix. Dieser setzt sich aus dem Klassifikator, '_Konfusionsmatrix_' und dem übergebenen identifier zusammen.\n",
    "        fig_name = classifiers[classifier_counter] + '_Konfusionsmatrix_' + identifier\n",
    "\n",
    "        # Abspeichern der Konfusionsmatrix in einem einzelnen Bild mit der im Kapitel Initialisierung definierten Funktion. Für eine verkürzte Ladezeit kann die Auflösung des Bildes in der Funktion save_fig reduziert werden.\n",
    "        save_fig(fig_name)\n",
    "\n",
    "        # Ausgabe unterdrücken\n",
    "        plt.close()\n",
    "\n",
    "        # Erhöhung des classifier_counter.\n",
    "        classifier_counter=classifier_counter+1\n",
    "\n",
    "    # Initialisierung eines Zählers classifier_counter um zusätzlich über die Namen aus der Liste classifier iterieren zu können.\n",
    "    classifier_counter = 0\n",
    "\n",
    "    # Iterieren über alle Wahrscheinlichkeiten für eine Klassenzuordnung in der Liste prediction_probas.\n",
    "    for prediction_proba in prediction_probas:\n",
    "\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(6,3))\n",
    "\n",
    "        #f.suptitle(classifiers[classifier_counter], fontsize=10) # Titel der Abbildung wurde auskommentiert und kann bei Bedarf durch Einkommentieren der Zeile wieder angegeben werden\n",
    "\n",
    "        # Auswahl der Wahrscheinlichkeiten, dass ein Element Klasse 1 zugeordnet wird.\n",
    "        prediction_proba = prediction_proba[:, 1]\n",
    "\n",
    "        # Berechnung und Ausgabe des Flächeninhalts AUROC.\n",
    "        auc = roc_auc_score(ps_test_labels, prediction_proba)\n",
    "\n",
    "        # Erzeugung zweier Serien von False-Positive- und True-Positive-Rate um anschließend den ROC Graphen zeichnen zu können.\n",
    "        fpr, tpr, _ = roc_curve(ps_test_labels, prediction_proba)\n",
    "\n",
    "        # Beschriftung des ROC Graphen mit dem Namen des Klassifikators und dem Flächeninhalt unter der Kurve.\n",
    "        label_roc = classifiers[classifier_counter] + ' (AUROC = %0.7f)'% auc\n",
    "\n",
    "        # Darstellung der ROC Kurve mit Angabe des Flächeninhalts AUROC auf 7 Nachkommastellen genau. Einzelne Klassierungsergebnisse können durch Punkte symbolisiert werden mit dem folgendem Source Code: marker='.',\n",
    "        ax1.plot(fpr, tpr, label=label_roc)\n",
    "\n",
    "        # Titel\n",
    "        ax1.set_title('ROC Plot')\n",
    "        # Axenbeschriftungen\n",
    "        ax1.set(xlabel='False Positive Rate', ylabel='True Positive Rate')\n",
    "        # Legende\n",
    "        ax1.legend()\n",
    "\n",
    "        # Anzeigen des Funktionsgraphen\n",
    "        # plt.show()\n",
    "\n",
    "        # Erzeugung zweier Serien von Precision und Recall, um anschließend den PR Graphen zeichnen zu können\n",
    "        precision, recall, thresholds = precision_recall_curve(ps_test_labels, prediction_proba)\n",
    "\n",
    "        # Berechnung der Average Precision (vgl. https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html).\n",
    "        precision_avg = average_precision_score(ps_test_labels, prediction_proba)\n",
    "\n",
    "        label_pr = classifiers[classifier_counter] + ' (PR_AVG = %0.7f)'% precision_avg\n",
    "\n",
    "        # Darstellung der Precision-Recall Kurve. Einzelne Klassierungsergebnisse können durch Punkte symbolisiert werden mit dem folgendem Source Code: marker='.',\n",
    "        ax2.plot(recall, precision, label=label_pr)\n",
    "\n",
    "        # Titel\n",
    "        ax2.set_title('PR Plot')\n",
    "        # Axenbeschriftungen\n",
    "        ax2.set(xlabel='Recall', ylabel='Precision')\n",
    "        # Legende\n",
    "        ax2.legend()\n",
    "\n",
    "        # Erzeugung eines Namens für den Plot. Dieser setzt sich aus dem Klassifikator, '_ROC_PR_' und dem übergebenen identifier zusammen.\n",
    "        fig_name = classifiers[classifier_counter] + '_ROC_PR_' + identifier\n",
    "\n",
    "        # Abspeichern des PR Plot in einem einzelnen Bild mit der im Kapitel Initialisierung definierten Funktion. Für eine verkürzte Ladezeit kann die Auflösung des Bildes in der Funktion save_fig reduziert werden.\n",
    "        save_fig(fig_name)\n",
    "\n",
    "        # Einstellung damit sich die beiden Grafiken der Abbildung nicht überschneiden.\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Ausgabe unterdrücken.\n",
    "        plt.close()\n",
    "\n",
    "        # Erhöhung des classifier_counter.\n",
    "        classifier_counter=classifier_counter+1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Funktion um aus einem Datensatz (bestehend aus den Attributsausprägungen X und den Klassenzuordnungen y) alle Elemente einer Klasse herauszufiltern. In diesem Fall wird die Funktion dazu genutzt die Minderheit herauszufiltern und die Mehrheit zu entfernen."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def filter_minority(X, y, majority_class):\n",
    "\n",
    "    i=0\n",
    "    index_list=[]\n",
    "    while i<len(X):\n",
    "        if y[i]==majority_class:\n",
    "            index_list.append(i)\n",
    "        i +=1\n",
    "    print(index_list)\n",
    "    X.drop(index_list, inplace=True)\n",
    "    minority = X.to_numpy()\n",
    "\n",
    "    return minority"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Methode um die Anwendung von pySMOTE an die Verwendung der restlichen Oversampling-Methoden anzugleichen"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def smote_rectangle(X ,y, minority_class, majority_class, ratio=None, neighbors=5):\n",
    "\n",
    "    # Herausfiltern der Minderheit aus dem Trainingsdatensatz\n",
    "    ps_train_labels_new = y.reset_index(drop=True)\n",
    "    ps_train_prepared_transformed_new = X.reset_index(drop=True)\n",
    "    minority = filter_minority(ps_train_prepared_transformed_new, ps_train_labels_new, majority_class)\n",
    "\n",
    "    # Formel, um die Menge an neu zu generierenden Punkten auf eine Anzahl zu erhöhen, welche die Anteile beider Klassen im Datensatz auf 50% setzt.\n",
    "    if ratio is not None:\n",
    "        ratio=ratio\n",
    "    else:\n",
    "        ratio = int(((len(y)/len(minority)) - 1)*100)\n",
    "        subtraction = int(((len(y)/len(minority)) - 1)*100)%100\n",
    "        ratio-=subtraction\n",
    "\n",
    "    # Initialisierung und Anwendung der Funktion SMOTE aus dem Modul pySMOTE auf die Minderheit des Trainingsdatensatzes\n",
    "    smote = pySMOTE.SMOTE(ratio=ratio, k_neighbors=neighbors)\n",
    "    new_samples = smote.oversample(minority, merge=True)\n",
    "\n",
    "    # Anlegen einer Spalte für die Klassenzugehörigkeiten der neuen Datenpunkte\n",
    "    if minority_class==1:\n",
    "        label_column = pd.DataFrame(1, index=np.arange(len(new_samples)), columns=['target'])\n",
    "    else:\n",
    "        label_column = pd.DataFrame(0, index=np.arange(len(new_samples)), columns=['target'])\n",
    "\n",
    "    # Zusammenführung des alten Datensatzes mit den neu generierten Datenpunkten\n",
    "    X = X.to_numpy()\n",
    "    y = y.to_numpy()\n",
    "    label_column = label_column.to_numpy()\n",
    "    label_column = label_column.reshape(len(label_column),)\n",
    "\n",
    "\n",
    "    X_res = np.concatenate((X, new_samples))\n",
    "    y_res = np.concatenate((y, label_column))\n",
    "\n",
    "    X_res = pd.DataFrame(X_res)\n",
    "    y_res = pd.DataFrame(y_res)\n",
    "\n",
    "\n",
    "    y_res[0] = y_res[0].astype(str)\n",
    "\n",
    "\n",
    "    i=0\n",
    "    while i<len(y_res):\n",
    "        if y_res[0][i]=='1.0':\n",
    "            y_res[0][i]='1'\n",
    "        if y_res[0][i]=='0.0':\n",
    "            y_res[0][i]='0'\n",
    "        i +=1\n",
    "\n",
    "    y_res[0] = y_res[0].astype(int)\n",
    "\n",
    "    # Rückgabe des Trainingsdatensatzes, welcher nun die zusätzlich generierten Datenpunkte enthält.\n",
    "    return X_res, y_res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Einstellungen für die verschiedenen Funktionen"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Um für mehrere Durchläufe des Notebooks die gleichen Ergebnisse zu erzeugen wird der Seed des RNG festgelegt.\n",
    "np.random.seed(42)\n",
    "\n",
    "# Einstellungen für die Achsenbeschriftungen.\n",
    "mpl.rc('axes', labelsize=20)\n",
    "mpl.rc('xtick', labelsize=13)\n",
    "mpl.rc('ytick', labelsize=13)\n",
    "\n",
    "# Erstellung eines Speicherort für die Graphen\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"ps_project_\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nun wird die zuvor definierte Funktionen zum Laden der Daten genutzt und es werden die ersten fünf Datenpunkte ausgegeben."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ps_data = load_ps_data()\n",
    "ps_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualisierung\n",
    "In diesem Kapitel werden einige Attribute des Datensatzes in Histogrammen visualisiert und als Bilder abgespeichert. Bei der Visualisierung des gesamten Datensatzes haben sich diese als repräsentativ herausgestellt. Die Visualisierung und Abspeicherung aller Attribute ist im Anschluss (aufgrund der langen Laufzeit) auskommentiert angegeben.\n",
    "\n",
    "Visualisierung des Histogramms des Attributs 'ps_car_01_cat'."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ax = ps_data['ps_car_01_cat'].hist(bins=12)\n",
    "ax.set_title('ps_car_01_cat', fontsize=15)\n",
    "save_fig('histo_ps_car_01_cat')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Visualisierung des Attributs 'ps_ind_08_bin'."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ax = ps_data['ps_ind_08_bin'].value_counts().plot(kind='bar', rot=0)\n",
    "ax.set_title('ps_ind_08_bin', fontsize=15)\n",
    "\n",
    "save_fig('histo_ps_ind_08_bin')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Visualisierung des Attributs 'ps_calc_01'."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ax = ps_data['ps_calc_01'].hist(bins=10)\n",
    "ax.set_title('ps_calc_01', fontsize=15)\n",
    "save_fig('histo_ps_calc_01')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Visualisierung des Attributs 'ps_calc_14'."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ax = ps_data['ps_calc_14'].hist(bins=24)\n",
    "ax.set_title('ps_calc_14', fontsize=15)\n",
    "save_fig('histo_ps_calc_14')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Visualisierung des Attributs 'ps_reg_03'."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ax = ps_data['ps_reg_03'].hist(bins=50)\n",
    "ax.set_title('ps_reg_03', fontsize=15)\n",
    "save_fig('histo_ps_reg_03')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualisierung des Datensatzes ps_data in Histogrammen mit jeweils bis zu 50 Säulen (bins=50).\n",
    "# figsize gibt die Größe der Darstellung in Zoll an.\n",
    "#ps_data.hist(bins=30, figsize=(60,40))\n",
    "# Abspeichern der Histogramme in einem einzelnen Bild mit der im Kapitel Initialisierung definierten Funktion. Für eine verkürzte Ladezeit kann die Auflösung des Bildes in der Funktion save_fig reduziert werden.\n",
    "#save_fig(\"attribute_histogram_plots_ps_data\")\n",
    "# Anzeigen der Histogramme mit dem Modul matplotlib.pyplot.\n",
    "#plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Analyse\n",
    "In diesem Kapitel wird der Datensatz aufgespalten, sodass Machine Learning Algorithmen einen Großteil des Datensatzes für ihr Training verwenden können. Zudem werden einige Features entfernt und transformiert. Im Anschluss sollen die Algorithmen auf einem Testdatensatz (dem übrig gebliebenen kleineren Teil) ausgewertet werden. Die Auswertung erfolgt anhand von verschiedenen Bewertungskennzahlen und -methoden. Grundlage für alle Bewertungskennzahlen und -methoden bilden dabei die absoluten Häufigkeiten in der Konfusionsmatrix. Im Anschluss an diese erste Auswertung folgen zwei weitere Trainings- und Auswertungszyklen. Vor dem zweiten Trainings- und Auswertungszyklus wird der Trainingsdatensatz mit verschiedenen Oversampling-Algorithmen modifiziert. Vor dem dritten Trainings- und Auswertungszyklus werden Kombinationen von Oversampling-Algorithmen ausprobiert."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Training 1\n",
    "Nach der Datentransformation werden nun erneut die Machine Learning Algorithmen trainiert. Zusätzlich wird ein K-Nearest-Neighbor Algorithmus trainiert. Dies ist nun nach der Transformation ungeordneter kategorischer Merkmale möglich."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Aufspalten des Datensatzes in Klassenzuordnungen und Merkmalsausprägungen."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Abspeichern der Klassenzuordnungen (ursprüngliche \"target\"-Spalte) in der Variable ps_labels\n",
    "ps_labels = ps_data[\"target\"].copy()\n",
    "# Abspeichern der Merkmalsausprägungen in der Variable ps_prepared\n",
    "# axis=1 bedeutet, dass sich \"target\" auf eine Spalte bezieht\n",
    "ps_prepared = ps_data.drop([\"target\", \"id\"], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Aufspalten von Klassenzuordnungen und Merkmalsausprägungen in jeweils eine Trainings- und eine Testversion. 80% des Datensatzes wird für das Training genutzt und 20% für die Auswertung. Die Datensätze werden dabei stratifiziert. Das bedeutet, dass das Verhältnis an Klassenzuordnungen im gesamten Datensatz auch in den aufgeteilten Datensätzen widergespiegelt wird."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 80% der Daten werden für den Trainingsdatensatz genutzt, 20% für den Testdatensatz (test_size=0.2).\n",
    "# Der random_state wird auf 42 festgesetzt, damit das Ergebnis reproduzierbar ist.\n",
    "# stratify=ps_labels sorgt dafür, die Datensätze stratifiziert werden.\n",
    "ps_train_prepared, ps_test_prepared, ps_train_labels, ps_test_labels = train_test_split(ps_prepared, ps_labels, test_size=0.2, random_state=42, stratify=ps_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Datenmodifikation\n",
    "Die Daten werden im in der nachfolgenden Zelle durch einen Spaltentransformator transformiert.\n",
    "In diesem Spaltentransformator werden die nominalen Werte werden mit einem One-Hot-Encoder transformiert. Dieser wandelt nominale Attribute mit n Kategorien in n Abfragen nach jeweils einer Kategorie um. Kann die Abfrage nach der Kategorie mit Ja beantwortet werden, so wird eine 1 eingetragen. Im anderen Fall wird eine 0 eingetragen. Dies dient dem Zweck, dass nominale Merkmalsausprägungen durch die Abstandsmetrik des K-Nearest-Neighbor-Algorithmus sinnvoll interpretiert werden können."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "categorical_features = ['ps_ind_02_cat', 'ps_ind_04_cat', 'ps_ind_05_cat', 'ps_car_01_cat', 'ps_car_02_cat', 'ps_car_03_cat', 'ps_car_04_cat', 'ps_car_05_cat', 'ps_car_06_cat', 'ps_car_07_cat', 'ps_car_08_cat', 'ps_car_09_cat', 'ps_car_10_cat', 'ps_car_11_cat' ]\n",
    "\n",
    "# Transformation der nominalen Attribute\n",
    "column_trans = make_column_transformer(\n",
    "    (OneHotEncoder(), categorical_features),\n",
    "    # `passthrough` bedeutet, dass die übrigen Spalten unberührt bleiben, sparse_threshold=0 gibt immer einen bestimmten Datentyp zurück\n",
    "    remainder='passthrough', n_jobs=-1, sparse_threshold=0\n",
    ")\n",
    "\n",
    "ps_train_prepared_transformed=pd.DataFrame(column_trans.fit_transform(ps_train_prepared))\n",
    "ps_test_prepared_transformed=pd.DataFrame(column_trans.fit_transform(ps_test_prepared))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " Nun werden in den folgenden Zellen ein K-Nearest-Neighbors Algorithmus, zwei Entscheidungsbäume, zwei Random Forests und ein Gaussian Naive Bayes mit dem Trainingsdatensatz trainiert mit dem transformierten Trainingsdatensatz trainiert."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Anlegen einer Liste von Klassifikatoren.\n",
    "classifier_list_transformed = create_classifiers()\n",
    "\n",
    "# Trainieren der Klassifikatoren mit den transformierten Trainingsdaten.\n",
    "train_models(ps_train_prepared_transformed, ps_train_labels, classifier_list_transformed)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Klassierung 1\n",
    "In diesem Abschnitt werden die Daten im Testdatensatz durch die trainierten Algorithmen klassiert."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Klassierung und Berechnung der Wahrscheinlichkeiten für eine Klassenzuordnung für den Testdatensatz.\n",
    "predictions_transformed, prediction_probas_transformed = klassieren(ps_test_prepared_transformed, classifier_list_transformed)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Auswertung 1\n",
    "In diesem Abschnitt werden die Klassierungen der Klassifikatoren mit verschiedenen Bewertungskennzahlen und -methoden ausgewertet und die Abbildungen der Auswertung abgespeichert."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Auswertung der Klassierungen und berechneten Wahrscheinlichkeiten für eine Klassenzuordnung.\n",
    "auswerten(predictions_transformed, prediction_probas_transformed, '1')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![K-Nearest-Neighbors_Konfusionsmatrix](images/ps_project_calc/K-Nearest-Neighbors_Konfusionsmatrix_1.png)![Decision_Tree_Gini_Konfusionsmatrix](images/ps_project_calc/Decision_Tree_Gini_Konfusionsmatrix_1.png) ![Decision_Tree_Entropy_Konfusionsmatrix](images/ps_project_calc/Decision_Tree_Entropy_Konfusionsmatrix_1.png)\n",
    "![Random_Forest_Gini_Konfusionsmatrix](images/ps_project_calc/Random_Forest_Gini_Konfusionsmatrix_1.png)![Random_Forest_Entropy_Konfusionsmatrix](images/ps_project_calc/Random_Forest_Entropy_Konfusionsmatrix_1.png)![Gaussian_Naive_Bayes_Konfusionsmatrix](images/ps_project_calc/Gaussian_Naive_Bayes_Konfusionsmatrix_1.png)\n",
    "\n",
    "![K-Nearest-Neighbors_ROC_PR](images/ps_project_calc/K-Nearest-Neighbors_ROC_PR_1.png)\n",
    "![Decision_Tree_Gini_ROC_PR](images/ps_project_calc/Decision_Tree_Gini_ROC_PR_1.png)\n",
    "![Decision_Tree_Entropy_ROC_PR](images/ps_project_calc/Decision_Tree_Entropy_ROC_PR_1.png)\n",
    "![Random_Forest_Gini_ROC_PR](images/ps_project_calc/Random_Forest_Gini_ROC_PR_1.png)\n",
    "![Random_Forest_Entropy_ROC_PR](images/ps_project_calc/Random_Forest_Entropy_ROC_PR_1.png)\n",
    "![Gaussian_Naive_Bayes_ROC_PR](images/ps_project_calc/Gaussian_Naive_Bayes_ROC_PR_1.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Datenmodifikation 2\n",
    "In diesem Abschnitt werden auf die Datensätze Oversampling Methoden angewandt. Eine Illustration der Oversampling-Methoden mit den Auswirkungen auf die Entscheidungsregionen der hier ebenfalls verwendeten Klassifikatoren ist im Notebook 'Bsp_Oversampling(ROS, SMOTE, BSM, ADA)' zu finden. Die Abbildungen der Auswertung werden mit der Endung '_2*' abgespeichert. * steht hierbei für die konkrete Oversampling-Methode in der Versuchsreihe. Die Reihenfolge ist: ROS, SMOTE_Rechteck, SMOTE_Linie, Borderline_SMOTE, ADASYN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Der Random Oversampler wird auf den transformierten Datensatz angewandt."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Festlegen des random_state auf 42 damit das Ergebnis reproduzierbar bleibt.\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "# Resampling der Trainingsdaten (also Features und Labels)\n",
    "ps_train_prepared_transformed_ros, ps_train_labels_transformed_ros = ros.fit_resample(ps_train_prepared_transformed, ps_train_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Anwendung von SMOTE mit der Interpolationsmethode Rechteck. Hierbei werden die neuen Datenpunkte in einem Rechteck generiert, welches von den zwei erzeugenden Datenpunkten aufgespannt wird. Eine Illustration ist im Notebook 'Erzeugung_Datenpunkt_SMOTE_Rechteck' zu finden."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ps_train_prepared_transformed_sm_rectangle, ps_train_labels_transformed_sm_rectangle = smote_rectangle(ps_train_prepared_transformed, ps_train_labels, 1, 0)\n",
    "\n",
    "ps_train_labels_transformed_sm_rectangle = ps_train_labels_transformed_sm_rectangle.values.ravel()\n",
    "ps_train_prepared_transformed_sm_rectangle_np = ps_train_prepared_transformed_sm_rectangle.to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "SMOTE mit der Interpolationsmethode Linie wird auf den transformierten Datensatz angewandt. Hierbei werden die neuen Datenpunkte auf einer Verbindungslinie zwischen zwei erzeugenden Datenpunkten generiert. Eine Illustration ist im Notebook 'Erzeugung_Datenpunkt_SMOTE_Linie' zu finden."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Festlegen des random_state auf 42 damit das Ergebnis reproduzierbar bleibt. n_jobs=-1 bedeutet, dass für die Berechnungen alle Kerne des CPU genutzt werden (--> schneller). Sonst werden die Standardparameter genutzt.\n",
    "sm = SMOTE(random_state=42, n_jobs=-1)\n",
    "\n",
    "# Resampling der Trainingsdaten (also Features und Labels)\n",
    "ps_train_prepared_transformed_sm, ps_train_labels_transformed_sm = sm.fit_resample(ps_train_prepared_transformed, ps_train_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Borderline SMOTE wird auf den transformierten Datensatz angewandt."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Festlegen des random_state auf 42 damit das Ergebnis reproduzierbar bleibt. n_jobs=-1 bedeutet, dass für die Berechnungen alle Kerne des CPU genutzt werden (--> schneller). Sonst werden die Standardparameter genutzt.\n",
    "bsm = BorderlineSMOTE(random_state=42, n_jobs=-1)\n",
    "\n",
    "# Resampling der Trainingsdaten (also Features und Labels)\n",
    "ps_train_prepared_transformed_bsm, ps_train_labels_transformed_bsm = bsm.fit_resample(ps_train_prepared_transformed, ps_train_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "ADASYN wird auf den transformierten Datensatz angewandt."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Festlegen des random_state auf 42 damit das Ergebnis reproduzierbar bleibt. n_jobs=-1 bedeutet, dass für die Berechnungen alle Kerne des CPU genutzt werden (--> schneller). Sonst werden die Standardparameter genutzt.\n",
    "ada = ADASYN(random_state=42, n_jobs=-1)\n",
    "\n",
    "# Resampling der Trainingsdaten (also Features und Labels)\n",
    "ps_train_prepared_transformed_ada, ps_train_labels_transformed_ada = ada.fit_resample(ps_train_prepared_transformed, ps_train_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Training 2.1\n",
    "\n",
    "Die Klassifikatoren werden mit den transformierten und durch Random Oversampling balancierten Trainingsdaten trainiert."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Anlegen einer Liste von Klassifikatoren.\n",
    "classifier_list_transformed_ros = create_classifiers()\n",
    "\n",
    "# Trainieren der Klassifikatoren mit den transformierten und durch Random Oversampling ausbalancierten Trainingsdaten.\n",
    "train_models(ps_train_prepared_transformed_ros, ps_train_labels_transformed_ros, classifier_list_transformed_ros)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Klassierung 2.1\n",
    "In diesem Abschnitt werden die Daten im Testdatensatz durch die trainierten Algorithmen klassiert."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Klassierung und Berechnung der Wahrscheinlichkeiten für eine Klassenzuordnung für den Testdatensatz.\n",
    "predictions_transformed_ros, prediction_probas_transformed_ros = klassieren(ps_test_prepared_transformed, classifier_list_transformed_ros)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Auswertung 2.1\n",
    "In diesem Abschnitt werden die Klassierungen der Klassifikatoren mit verschiedenen Bewertungskennzahlen und -methoden ausgewertet."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Auswertung der Klassierungen und berechneten Wahrscheinlichkeiten für eine Klassenzuordnung.\n",
    "auswerten(predictions_transformed_ros, prediction_probas_transformed_ros, '21')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![K-Nearest-Neighbors_Konfusionsmatrix](images/ps_project_calc/K-Nearest-Neighbors_Konfusionsmatrix_21.png)![Decision_Tree_Gini_Konfusionsmatrix](images/ps_project_calc/Decision_Tree_Gini_Konfusionsmatrix_21.png) ![Decision_Tree_Entropy_Konfusionsmatrix](images/ps_project_calc/Decision_Tree_Entropy_Konfusionsmatrix_21.png)\n",
    "![Random_Forest_Gini_Konfusionsmatrix](images/ps_project_calc/Random_Forest_Gini_Konfusionsmatrix_21.png)![Random_Forest_Entropy_Konfusionsmatrix](images/ps_project_calc/Random_Forest_Entropy_Konfusionsmatrix_21.png)![Gaussian_Naive_Bayes_Konfusionsmatrix](images/ps_project_calc/Gaussian_Naive_Bayes_Konfusionsmatrix_21.png)\n",
    "\n",
    "![K-Nearest-Neighbors_ROC_PR](images/ps_project_calc/K-Nearest-Neighbors_ROC_PR_21.png)\n",
    "![Decision_Tree_Gini_ROC_PR](images/ps_project_calc/Decision_Tree_Gini_ROC_PR_21.png)\n",
    "![Decision_Tree_Entropy_ROC_PR](images/ps_project_calc/Decision_Tree_Entropy_ROC_PR_21.png)\n",
    "![Random_Forest_Gini_ROC_PR](images/ps_project_calc/Random_Forest_Gini_ROC_PR_21.png)\n",
    "![Random_Forest_Entropy_ROC_PR](images/ps_project_calc/Random_Forest_Entropy_ROC_PR_21.png)\n",
    "![Gaussian_Naive_Bayes_ROC_PR](images/ps_project_calc/Gaussian_Naive_Bayes_ROC_PR_21.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Training 2.2.1\n",
    "Die Klassifikatoren werden mit den transformierten und durch SMOTE balancierten Trainingsdaten trainiert."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Anlegen einer Liste von Klassifikatoren.\n",
    "classifier_list_transformed_sm_rectangle = create_classifiers()\n",
    "\n",
    "# Trainieren der Klassifikatoren mit den transformierten und durch SMOTE ausbalancierten Trainingsdaten.\n",
    "train_models(ps_train_prepared_transformed_sm_rectangle, ps_train_labels_transformed_sm_rectangle, classifier_list_transformed_sm_rectangle)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Klassierung 2.2.1\n",
    "In diesem Abschnitt werden die Daten im Testdatensatz durch die trainierten Algorithmen klassiert."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Klassierung und Berechnung der Wahrscheinlichkeiten für eine Klassenzuordnung für den Testdatensatz.\n",
    "predictions_transformed_sm_rectangle, prediction_probas_transformed_sm_rectangle = klassieren(ps_test_prepared_transformed, classifier_list_transformed_sm_rectangle)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Auswertung 2.2.1\n",
    "In diesem Abschnitt werden die Klassierungen der Klassifikatoren mit verschiedenen Bewertungskennzahlen und -methoden ausgewertet."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Auswertung der Klassierungen und berechneten Wahrscheinlichkeiten für eine Klassenzuordnung.\n",
    "auswerten(predictions_transformed_sm_rectangle, prediction_probas_transformed_sm_rectangle, '22_1')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![K-Nearest-Neighbors_Konfusionsmatrix](images/ps_project_calc/K-Nearest-Neighbors_Konfusionsmatrix_22_1.png)![Decision_Tree_Gini_Konfusionsmatrix](images/ps_project_calc/Decision_Tree_Gini_Konfusionsmatrix_22_1.png) ![Decision_Tree_Entropy_Konfusionsmatrix](images/ps_project_calc/Decision_Tree_Entropy_Konfusionsmatrix_22_1.png)\n",
    "![Random_Forest_Gini_Konfusionsmatrix](images/ps_project_calc/Random_Forest_Gini_Konfusionsmatrix_22_1.png)![Random_Forest_Entropy_Konfusionsmatrix](images/ps_project_calc/Random_Forest_Entropy_Konfusionsmatrix_22_1.png)![Gaussian_Naive_Bayes_Konfusionsmatrix](images/ps_project_calc/Gaussian_Naive_Bayes_Konfusionsmatrix_22_1.png)\n",
    "\n",
    "![K-Nearest-Neighbors_ROC_PR](images/ps_project_calc/K-Nearest-Neighbors_ROC_PR_22_1.png)\n",
    "![Decision_Tree_Gini_ROC_PR](images/ps_project_calc/Decision_Tree_Gini_ROC_PR_22_1.png)\n",
    "![Decision_Tree_Entropy_ROC_PR](images/ps_project_calc/Decision_Tree_Entropy_ROC_PR_22_1.png)\n",
    "![Random_Forest_Gini_ROC_PR](images/ps_project_calc/Random_Forest_Gini_ROC_PR_22_1.png)\n",
    "![Random_Forest_Entropy_ROC_PR](images/ps_project_calc/Random_Forest_Entropy_ROC_PR_22_1.png)\n",
    "![Gaussian_Naive_Bayes_ROC_PR](images/ps_project_calc/Gaussian_Naive_Bayes_ROC_PR_22_1.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Training 2.2.2\n",
    "Die Klassifikatoren werden mit den transformierten und durch SMOTE balancierten Trainingsdaten trainiert."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Training 2.2.2\n",
    "Die Klassifikatoren werden mit den transformierten und durch SMOTE balancierten Trainingsdaten trainiert."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Anlegen einer Liste von Klassifikatoren.\n",
    "classifier_list_transformed_sm = create_classifiers()\n",
    "\n",
    "# Trainieren der Klassifikatoren mit den transformierten und durch SMOTE ausbalancierten Trainingsdaten.\n",
    "train_models(ps_train_prepared_transformed_sm, ps_train_labels_transformed_sm, classifier_list_transformed_sm)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Klassierung 2.2.2\n",
    "In diesem Abschnitt werden die Daten im Testdatensatz durch die trainierten Algorithmen klassiert."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Klassierung und Berechnung der Wahrscheinlichkeiten für eine Klassenzuordnung für den Testdatensatz.\n",
    "predictions_transformed_sm, prediction_probas_transformed_sm = klassieren(ps_test_prepared_transformed, classifier_list_transformed_sm)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Auswertung 2.2.2\n",
    "In diesem Abschnitt werden die Klassierungen der Klassifikatoren mit verschiedenen Bewertungskennzahlen und -methoden ausgewertet."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Auswertung der Klassierungen und berechneten Wahrscheinlichkeiten für eine Klassenzuordnung.\n",
    "auswerten(predictions_transformed_sm, prediction_probas_transformed_sm, '22_2')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![K-Nearest-Neighbors_Konfusionsmatrix](images/ps_project_calc/K-Nearest-Neighbors_Konfusionsmatrix_22_2.png)![Decision_Tree_Gini_Konfusionsmatrix](images/ps_project_calc/Decision_Tree_Gini_Konfusionsmatrix_22_2.png) ![Decision_Tree_Entropy_Konfusionsmatrix](images/ps_project_calc/Decision_Tree_Entropy_Konfusionsmatrix_22_2.png)\n",
    "![Random_Forest_Gini_Konfusionsmatrix](images/ps_project_calc/Random_Forest_Gini_Konfusionsmatrix_22_2.png)![Random_Forest_Entropy_Konfusionsmatrix](images/ps_project_calc/Random_Forest_Entropy_Konfusionsmatrix_22_2.png)![Gaussian_Naive_Bayes_Konfusionsmatrix](images/ps_project_calc/Gaussian_Naive_Bayes_Konfusionsmatrix_22_2.png)\n",
    "\n",
    "![K-Nearest-Neighbors_ROC_PR](images/ps_project_calc/K-Nearest-Neighbors_ROC_PR_22_2.png)\n",
    "![Decision_Tree_Gini_ROC_PR](images/ps_project_calc/Decision_Tree_Gini_ROC_PR_22_2.png)\n",
    "![Decision_Tree_Entropy_ROC_PR](images/ps_project_calc/Decision_Tree_Entropy_ROC_PR_22_2.png)\n",
    "![Random_Forest_Gini_ROC_PR](images/ps_project_calc/Random_Forest_Gini_ROC_PR_22_2.png)\n",
    "![Random_Forest_Entropy_ROC_PR](images/ps_project_calc/Random_Forest_Entropy_ROC_PR_22_2.png)\n",
    "![Gaussian_Naive_Bayes_ROC_PR](images/ps_project_calc/Gaussian_Naive_Bayes_ROC_PR_22_2.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Training 2.3\n",
    "Die Klassifikatoren werden mit den transformierten und durch Borderline SMOTE balancierten Trainingsdaten trainiert."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Anlegen einer Liste von Klassifikatoren.\n",
    "classifier_list_transformed_bsm = create_classifiers()\n",
    "\n",
    "# Trainieren der Klassifikatoren mit den transformierten und durch Borderline SMOTE ausbalancierten Trainingsdaten.\n",
    "train_models(ps_train_prepared_transformed_bsm, ps_train_labels_transformed_bsm, classifier_list_transformed_bsm)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Klassierung 2.3\n",
    "In diesem Abschnitt werden die Daten im Testdatensatz durch die trainierten Algorithmen klassiert."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Klassierung und Berechnung der Wahrscheinlichkeiten für eine Klassenzuordnung für den Testdatensatz.\n",
    "predictions_transformed_bsm, prediction_probas_transformed_bsm = klassieren(ps_test_prepared_transformed, classifier_list_transformed_bsm)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Auswertung 2.3\n",
    "In diesem Abschnitt werden die Klassierungen der Klassifikatoren mit verschiedenen Bewertungskennzahlen und -methoden ausgewertet."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Auswertung der Klassierungen und berechneten Wahrscheinlichkeiten für eine Klassenzuordnung.\n",
    "auswerten(predictions_transformed_bsm, prediction_probas_transformed_bsm, '23')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![K-Nearest-Neighbors_Konfusionsmatrix](images/ps_project_calc/K-Nearest-Neighbors_Konfusionsmatrix_23.png)![Decision_Tree_Gini_Konfusionsmatrix](images/ps_project_calc/Decision_Tree_Gini_Konfusionsmatrix_23.png) ![Decision_Tree_Entropy_Konfusionsmatrix](images/ps_project_calc/Decision_Tree_Entropy_Konfusionsmatrix_23.png)\n",
    "![Random_Forest_Gini_Konfusionsmatrix](images/ps_project_calc/Random_Forest_Gini_Konfusionsmatrix_23.png)![Random_Forest_Entropy_Konfusionsmatrix](images/ps_project_calc/Random_Forest_Entropy_Konfusionsmatrix_23.png)![Gaussian_Naive_Bayes_Konfusionsmatrix](images/ps_project_calc/Gaussian_Naive_Bayes_Konfusionsmatrix_23.png)\n",
    "\n",
    "![K-Nearest-Neighbors_ROC_PR](images/ps_project_calc/K-Nearest-Neighbors_ROC_PR_23.png)\n",
    "![Decision_Tree_Gini_ROC_PR](images/ps_project_calc/Decision_Tree_Gini_ROC_PR_23.png)\n",
    "![Decision_Tree_Entropy_ROC_PR](images/ps_project_calc/Decision_Tree_Entropy_ROC_PR_23.png)\n",
    "![Random_Forest_Gini_ROC_PR](images/ps_project_calc/Random_Forest_Gini_ROC_PR_23.png)\n",
    "![Random_Forest_Entropy_ROC_PR](images/ps_project_calc/Random_Forest_Entropy_ROC_PR_23.png)\n",
    "![Gaussian_Naive_Bayes_ROC_PR](images/ps_project_calc/Gaussian_Naive_Bayes_ROC_PR_23.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Training 2.4\n",
    "Die Klassifikatoren werden mit den transformierten und durch ADASYN balancierten Trainingsdaten trainiert."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Anlegen einer Liste von Klassifikatoren.\n",
    "classifier_list_transformed_ada = create_classifiers()\n",
    "\n",
    "# Trainieren der Klassifikatoren mit den transformierten und durch ADASYN ausbalancierten Trainingsdaten.\n",
    "train_models(ps_train_prepared_transformed_ada, ps_train_labels_transformed_ada, classifier_list_transformed_ada)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Klassierung 2.4\n",
    "In diesem Abschnitt werden die Daten im Testdatensatz durch die trainierten Algorithmen klassiert."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Klassierung und Berechnung der Wahrscheinlichkeiten für eine Klassenzuordnung für den Testdatensatz.\n",
    "predictions_transformed_ada, prediction_probas_transformed_ada = klassieren(ps_test_prepared_transformed, classifier_list_transformed_ada)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Auswertung 2.4\n",
    "In diesem Abschnitt werden die Klassierungen der Klassifikatoren mit verschiedenen Bewertungskennzahlen und -methoden ausgewertet."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Auswertung der Klassierungen und berechneten Wahrscheinlichkeiten für eine Klassenzuordnung.\n",
    "auswerten(predictions_transformed_ada, prediction_probas_transformed_ada, '24')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![K-Nearest-Neighbors_Konfusionsmatrix](images/ps_project_calc/K-Nearest-Neighbors_Konfusionsmatrix_24.png)![Decision_Tree_Gini_Konfusionsmatrix](images/ps_project_calc/Decision_Tree_Gini_Konfusionsmatrix_24.png) ![Decision_Tree_Entropy_Konfusionsmatrix](images/ps_project_calc/Decision_Tree_Entropy_Konfusionsmatrix_24.png)\n",
    "![Random_Forest_Gini_Konfusionsmatrix](images/ps_project_calc/Random_Forest_Gini_Konfusionsmatrix_24.png)![Random_Forest_Entropy_Konfusionsmatrix](images/ps_project_calc/Random_Forest_Entropy_Konfusionsmatrix_24.png)![Gaussian_Naive_Bayes_Konfusionsmatrix](images/ps_project_calc/Gaussian_Naive_Bayes_Konfusionsmatrix_24.png)\n",
    "\n",
    "![K-Nearest-Neighbors_ROC_PR](images/ps_project_calc/K-Nearest-Neighbors_ROC_PR_24.png)\n",
    "![Decision_Tree_Gini_ROC_PR](images/ps_project_calc/Decision_Tree_Gini_ROC_PR_24.png)\n",
    "![Decision_Tree_Entropy_ROC_PR](images/ps_project_calc/Decision_Tree_Entropy_ROC_PR_24.png)\n",
    "![Random_Forest_Gini_ROC_PR](images/ps_project_calc/Random_Forest_Gini_ROC_PR_24.png)\n",
    "![Random_Forest_Entropy_ROC_PR](images/ps_project_calc/Random_Forest_Entropy_ROC_PR_24.png)\n",
    "![Gaussian_Naive_Bayes_ROC_PR](images/ps_project_calc/Gaussian_Naive_Bayes_ROC_PR_24.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Experimente\n",
    "\n",
    "In diesem Abschnitt werden als Experiment zwei unterschiedliche Kombinationen von Oversampling Algorithmen genutzt, um den Trainingsdatensatz zu balancieren. Anschließend werden jeweils verschiedene Klassifikatoren mit diesen modifizierten Datensätzen trainiert und ausgewertet. Die Abbildungen der Auswertung werden mit der Endung '_3*' abgespeichert. * steht hierbei für die konkrete Oversampling-Methode in der Versuchsreihe."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Datenmodifikation 3.1\n",
    "Als erstes Experiment soll ausgetestet werden, welchen Einfluss ein Training unterschiedlicher Oversampling Algorithmen auf gleich große Teile des ursprünglichen Trainingsdatensatz hat, welche im Anschluss wieder zu einem großen Trainingsdatensatz zusammengesetzt werden."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Zweimaliges Aufspalten in insgesamt 4 gleich große Teile\n",
    "\n",
    "# Datensatz halbieren\n",
    "# Der random_state wird auf 42 festgesetzt, damit das Ergebnis reproduzierbar ist.\n",
    "# stratify=ps_labels sorgt dafür, die Datensätze stratifiziert werden.\n",
    "ps_train_prepared_transformed_0, ps_train_prepared_transformed_1, ps_train_labels_0, ps_train_labels_1 = train_test_split(ps_train_prepared_transformed, ps_train_labels, test_size=0.5, random_state=42, stratify=ps_train_labels)\n",
    "\n",
    "# Halbe Datensätze halbieren zu Vierteln\n",
    "ps_train_prepared_transformed_0_0, ps_train_prepared_transformed_0_1, ps_train_labels_0_0, ps_train_labels_0_1 = train_test_split(ps_train_prepared_transformed_0, ps_train_labels_0, test_size=0.5, random_state=42, stratify=ps_train_labels_0)\n",
    "ps_train_prepared_transformed_1_0, ps_train_prepared_transformed_1_1, ps_train_labels_1_0, ps_train_labels_1_1 = train_test_split(ps_train_prepared_transformed_1, ps_train_labels_1, test_size=0.5, random_state=42, stratify=ps_train_labels_1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Oversampling Algorithmen auf die Datensätze anwenden: _0_0 = ROS; _0_1 = SMOTE; _1_0 = ADASYN; _1_1 = Borderline SMOTE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ps_train_prepared_transformed_0_0_ros, ps_train_labels_0_0_ros = ros.fit_resample(ps_train_prepared_transformed_0_0, ps_train_labels_0_0)\n",
    "\n",
    "ps_train_prepared_transformed_0_1_sm, ps_train_labels_0_1_sm = sm.fit_resample(ps_train_prepared_transformed_0_1, ps_train_labels_0_1)\n",
    "\n",
    "ps_train_prepared_transformed_1_0_ada, ps_train_labels_1_0_ada = ada.fit_resample(ps_train_prepared_transformed_1_0, ps_train_labels_1_0)\n",
    "\n",
    "ps_train_prepared_transformed_1_1_bsm, ps_train_labels_1_1_bsm = bsm.fit_resample(ps_train_prepared_transformed_1_1, ps_train_labels_1_1)\n",
    "\n",
    "# Überführung in ein Dataframe\n",
    "ps_train_prepared_transformed_0_0_ros = pd.DataFrame(ps_train_prepared_transformed_0_0_ros)\n",
    "ps_train_labels_0_0_ros = pd.DataFrame(ps_train_labels_0_0_ros)\n",
    "ps_train_prepared_transformed_0_1_sm = pd.DataFrame(ps_train_prepared_transformed_0_1_sm)\n",
    "ps_train_labels_0_1_sm = pd.DataFrame(ps_train_labels_0_1_sm)\n",
    "ps_train_prepared_transformed_1_0_ada = pd.DataFrame(ps_train_prepared_transformed_1_0_ada)\n",
    "ps_train_labels_1_0_ada = pd.DataFrame(ps_train_labels_1_0_ada)\n",
    "ps_train_prepared_transformed_1_1_bsm = pd.DataFrame(ps_train_prepared_transformed_1_1_bsm)\n",
    "ps_train_labels_1_1_bsm = pd.DataFrame(ps_train_labels_1_1_bsm)\n",
    "\n",
    "# Zusammenfügen der Datensätze\n",
    "ps_train_x1 = pd.concat([ps_train_prepared_transformed_0_0_ros,ps_train_prepared_transformed_0_1_sm, ps_train_prepared_transformed_1_0_ada, ps_train_prepared_transformed_1_1_bsm], axis=0)\n",
    "ps_train_labels_x1 = pd.concat([ps_train_labels_0_0_ros,ps_train_labels_0_1_sm, ps_train_labels_1_0_ada, ps_train_labels_1_1_bsm], axis=0)\n",
    "ps_train_labels_x1 = ps_train_labels_x1.values.ravel()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Training 3.1\n",
    "Die Klassifikatoren werden mit den Trainingsdaten aus 4 verschiedenen parallelen Oversampling Algorithmen trainiert."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Anlegen einer Liste von Klassifikatoren.\n",
    "classifier_list_x1 = create_classifiers()\n",
    "\n",
    "# Trainieren der Klassifikatoren mit den gemäß Experiment 1 abgeänderten Trainingsdaten.\n",
    "train_models(ps_train_x1, ps_train_labels_x1, classifier_list_x1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Klassierung 3.1\n",
    "In diesem Abschnitt werden die Daten im Testdatensatz durch die trainierten Algorithmen klassiert."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Klassierung und Berechnung der Wahrscheinlichkeiten für eine Klassenzuordnung für den Testdatensatz.\n",
    "predictions_x1, prediction_probas_x1 = klassieren(ps_test_prepared_transformed, classifier_list_x1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Auswertung 3.1\n",
    "In diesem Abschnitt werden die Klassierungen der Klassifikatoren mit verschiedenen Bewertungskennzahlen und -methoden ausgewertet."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Auswertung der Klassierungen und berechneten Wahrscheinlichkeiten für eine Klassenzuordnung.\n",
    "auswerten(predictions_x1, prediction_probas_x1, '31')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![K-Nearest-Neighbors_Konfusionsmatrix](images/ps_project_calc/K-Nearest-Neighbors_Konfusionsmatrix_31.png)![Decision_Tree_Gini_Konfusionsmatrix](images/ps_project_calc/Decision_Tree_Gini_Konfusionsmatrix_31.png) ![Decision_Tree_Entropy_Konfusionsmatrix](images/ps_project_calc/Decision_Tree_Entropy_Konfusionsmatrix_31.png)\n",
    "![Random_Forest_Gini_Konfusionsmatrix](images/ps_project_calc/Random_Forest_Gini_Konfusionsmatrix_31.png)![Random_Forest_Entropy_Konfusionsmatrix](images/ps_project_calc/Random_Forest_Entropy_Konfusionsmatrix_31.png)![Gaussian_Naive_Bayes_Konfusionsmatrix](images/ps_project_calc/Gaussian_Naive_Bayes_Konfusionsmatrix_31.png)\n",
    "\n",
    "![K-Nearest-Neighbors_ROC_PR](images/ps_project_calc/K-Nearest-Neighbors_ROC_PR_31.png)\n",
    "![Decision_Tree_Gini_ROC_PR](images/ps_project_calc/Decision_Tree_Gini_ROC_PR_31.png)\n",
    "![Decision_Tree_Entropy_ROC_PR](images/ps_project_calc/Decision_Tree_Entropy_ROC_PR_31.png)\n",
    "![Random_Forest_Gini_ROC_PR](images/ps_project_calc/Random_Forest_Gini_ROC_PR_31.png)\n",
    "![Random_Forest_Entropy_ROC_PR](images/ps_project_calc/Random_Forest_Entropy_ROC_PR_31.png)\n",
    "![Gaussian_Naive_Bayes_ROC_PR](images/ps_project_calc/Gaussian_Naive_Bayes_ROC_PR_31.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Datenmodifikation 3.2\n",
    "Als zweites Experiment wird ausgetestet, welchen Einfluss ein geschachteltes Training unterschiedlicher Oversampling Algorithmen auf den Trainingsdatensatz hat. Die Minderheit wird dabei durch jede Oversampling-Methode vergrößert, bis sie gleich groß wie die ursprüngliche Mehrheit ist."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ada_x2 = ADASYN(random_state=42, n_jobs=-1, sampling_strategy=0.25)\n",
    "bsm_x2 = BorderlineSMOTE(random_state=42, n_jobs=-1, sampling_strategy=0.5)\n",
    "sm_x2 = SMOTE(random_state=42, n_jobs=-1, sampling_strategy=0.75)\n",
    "ros_x2 = RandomOverSampler(random_state=42)\n",
    "\n",
    "# Oversampling durch ADASYN bis Anzahl an Datenpunkten der Minderheit 25% der Anzahl an Datenpunkten der Mehrheit erreicht hat.\n",
    "ps_train_prepared_transformed_ada_x2, ps_train_labels_ada_x2 = ada_x2.fit_resample(ps_train_prepared_transformed, ps_train_labels)\n",
    "\n",
    "# Oversampling durch BorderlineSMOTE bis Anzahl an Datenpunkten der Minderheit 50% der Anzahl an Datenpunkten der Mehrheit erreicht hat.\n",
    "ps_train_prepared_transformed_ada_bsm_x2, ps_train_labels_ada_bsm_x2 = bsm_x2.fit_resample(ps_train_prepared_transformed_ada_x2, ps_train_labels_ada_x2)\n",
    "\n",
    "# Oversampling durch SMOTE (Linie) bis Anzahl an Datenpunkten der Minderheit 75% der Anzahl an Datenpunkten der Mehrheit erreicht hat.\n",
    "ps_train_prepared_transformed_ada_bsm_sm_x2, ps_train_labels_ada_bsm_sm_x2 = sm_x2.fit_resample(ps_train_prepared_transformed_ada_bsm_x2, ps_train_labels_ada_bsm_x2)\n",
    "\n",
    "# Oversampling durch den RandomOverSampler bis Anzahl an Datenpunkten der Minderheit 100% der Anzahl an Datenpunkten der Mehrheit erreicht hat.\n",
    "ps_train_prepared_transformed_ada_bsm_sm_ros_x2, ps_train_labels_ada_bsm_sm_ros_x2 = ros_x2.fit_resample(ps_train_prepared_transformed_ada_bsm_sm_x2, ps_train_labels_ada_bsm_sm_x2)\n",
    "\n",
    "ps_train_x2 = ps_train_prepared_transformed_ada_bsm_sm_ros_x2\n",
    "ps_train_labels_x2 = ps_train_labels_ada_bsm_sm_ros_x2\n",
    "ps_train_labels_x2 = ps_train_labels_x2.values.ravel()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Training 3.2\n",
    "Die Klassifikatoren werden mit den Trainingsdaten aus 4 ineinander geschachtelten Oversampling Algorithmen trainiert."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Anlegen einer Liste von Klassifikatoren.\n",
    "classifier_list_x2 = create_classifiers()\n",
    "\n",
    "# Trainieren der Klassifikatoren mit den gemäß Experiment 1 abgeänderten Trainingsdaten.\n",
    "train_models(ps_train_x2, ps_train_labels_x2, classifier_list_x2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Klassierung 3.2\n",
    "In diesem Abschnitt werden die Daten im Testdatensatz `ps_test_prepared` durch die trainierten Algorithmen klassiert."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Klassierung und Berechnung der Wahrscheinlichkeiten für eine Klassenzuordnung für den Testdatensatz.\n",
    "predictions_x2, prediction_probas_x2 = klassieren(ps_test_prepared_transformed, classifier_list_x2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Auswertung 3.2\n",
    "In diesem Abschnitt werden die Klassierungen der Klassifikatoren mit verschiedenen Bewertungskennzahlen und -methoden ausgewertet."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Auswertung der Klassierungen und berechneten Wahrscheinlichkeiten für eine Klassenzuordnung.\n",
    "auswerten(predictions_x2, prediction_probas_x2, '32')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![K-Nearest-Neighbors_Konfusionsmatrix](images/ps_project_calc/K-Nearest-Neighbors_Konfusionsmatrix_32.png)![Decision_Tree_Gini_Konfusionsmatrix](images/ps_project_calc/Decision_Tree_Gini_Konfusionsmatrix_32.png) ![Decision_Tree_Entropy_Konfusionsmatrix](images/ps_project_calc/Decision_Tree_Entropy_Konfusionsmatrix_32.png)\n",
    "![Random_Forest_Gini_Konfusionsmatrix](images/ps_project_calc/Random_Forest_Gini_Konfusionsmatrix_32.png)![Random_Forest_Entropy_Konfusionsmatrix](images/ps_project_calc/Random_Forest_Entropy_Konfusionsmatrix_32.png)![Gaussian_Naive_Bayes_Konfusionsmatrix](images/ps_project_calc/Gaussian_Naive_Bayes_Konfusionsmatrix_32.png)\n",
    "\n",
    "![K-Nearest-Neighbors_ROC_PR](images/ps_project_calc/K-Nearest-Neighbors_ROC_PR_32.png)\n",
    "![Decision_Tree_Gini_ROC_PR](images/ps_project_calc/Decision_Tree_Gini_ROC_PR_32.png)\n",
    "![Decision_Tree_Entropy_ROC_PR](images/ps_project_calc/Decision_Tree_Entropy_ROC_PR_32.png)\n",
    "![Random_Forest_Gini_ROC_PR](images/ps_project_calc/Random_Forest_Gini_ROC_PR_32.png)\n",
    "![Random_Forest_Entropy_ROC_PR](images/ps_project_calc/Random_Forest_Entropy_ROC_PR_32.png)\n",
    "![Gaussian_Naive_Bayes_ROC_PR](images/ps_project_calc/Gaussian_Naive_Bayes_ROC_PR_32.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}