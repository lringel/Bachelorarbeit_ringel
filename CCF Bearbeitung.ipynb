{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Credit Card Fraud Detection Notebook\n",
    "In diesem Notebook wird der Datensatz Credit Card Fraud Detection aus einem Wettbewerb der Online-Community kaggle analysiert. Er ist unter dem folgenden Link erhältlich: <https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud>\n",
    "Die Ordnerstruktur für den Zugriff auf diesen Datensatz mit diesem Notebook ist dabei im Speicherort des Source Codes folgendermaßen anzulegen: `datasets/ccf/ccf.csv`. Im README des Github Repositories befindet sich ein Link zum Herunterladen zweier Datensätze in der passenden Ordnerstruktur. Dieser ist bis zum 01.08.2022 gültig.\n",
    "Der Datensatz enthält Transaktionsdaten über Kreditkartenzahlungen, welche im September 2013 in einem Zeitraum von 2 Tagen von europäischen Kreditkarteninhaber:innen getätigt wurden und soll zur Betrugserkennung bei Transaktionen genutzt werden. Von insgesamt 284.807 Transaktionen, sind 492 auf einen Betrug zurückzuführen. Der Datensatz weist damit ein hohes Ungleichgewicht auf, denn die betrügerischen Transaktionen bilden einen Anteil von 0,173%. Die Information über die Klassenzugehörigkeit ist in der Spalte Class abgespeichert. Eine 1 steht für einen Betrugsfall und eine 0 für eine legitime Zahlung. Alle 30 Attribute sind numerische Variablen. 28 dieser Attribute sind Ergebnis eine Principal Component Analyse gewonnen. Die fachliche Bedeutung der ursprünglichen Attribute ist aus Datenschutzgründen nicht angegeben. Die Bedeutung der anderen zwei Attribute ist bekannt. Diese zwei Attribute heißen `Time` und `Amount`. `Time` beschreibt dabei die Zeit in Sekunden, die seit der ersten Transaktion im Datensatz vergangen sind. `Amount` gibt die Höhe der Transaktion an. Die Analyse umfasst das Training sechs verschiedener Klassifikatoren auf verschiedenen Iterationen eines Trainingsdatensatz, welcher mit sieben unterschiedlichen Oversampling-Methoden ausbalanciert wird.\n",
    "Das Notebook ist dabei in folgende Kapitel unterteilt:\n",
    "\n",
    "- **Initialisierung**: Importierungen und Einstellungen für nachfolgende Notebook Kapitel und Laden des Datensatzes.\n",
    "- **Visualisierung**: Visualisierung der Verteilungen der einiger Attribute des Datensatzes.\n",
    "- **Analyse**:\n",
    "    - ***Training 1***: Aufspaltung des Datensatzes in Features und Labels. Training verschiedener Algorithmen für das binäre Klassifikationsproblem.\n",
    "    - ***Klassierung 1***: Klassierung der Testdaten.\n",
    "    - ***Auswertung 1***: Auswertungen der Ergebnisse mittels verschiedener Bewertungskennzahlen und -methoden, welche sich aus der Konfusionsmatrix ableiten lassen.\n",
    "    - ***Datenmodifikation 2***: Modifikation der Daten durch Oversampling-Algorithmen.\n",
    "    - ***Training 2.1***: Training verschiedener Algorithmen mit durch Random Oversampling modifizierten Trainingsdaten für das binäre Klassifikationsproblem.\n",
    "    - ***Klassierung 2.1***: Klassierung der durch Random Oversampling modifizierten Testdaten.\n",
    "    - ***Auswertung 2.1***: Auswertungen der Ergebnisse mittels verschiedener Bewertungskennzahlen und -methoden, welche sich aus der Konfusionsmatrix ableiten lassen.\n",
    "    - ***Training 2.2.1***: Training verschiedener Algorithmen mit durch SMOTE (Rechteck) modifizierten Trainingsdaten für das binäre Klassifikationsproblem.\n",
    "    - ***Klassierung 2.2.1***: Klassierung der durch SMOTE (Rechteck) modifizierten Testdaten.\n",
    "    - ***Auswertung 2.2.1***: Auswertungen der Ergebnisse mittels verschiedener Bewertungskennzahlen und -methoden, welche sich aus der Konfusionsmatrix ableiten lassen.\n",
    "    - ***Training 2.2.2***: Training verschiedener Algorithmen mit durch SMOTE (Linie) modifizierten Trainingsdaten für das binäre Klassifikationsproblem.\n",
    "    - ***Klassierung 2.2.2***: Klassierung der durch SMOTE (Linie) modifizierten Testdaten.\n",
    "    - ***Auswertung 2.2.2***: Auswertungen der Ergebnisse mittels verschiedener Bewertungskennzahlen und -methoden, welche sich aus der Konfusionsmatrix ableiten lassen.\n",
    "    - ***Training 2.3***: Training verschiedener Algorithmen mit durch Borderline SMOTE modifizierten Trainingsdaten für das binäre Klassifikationsproblem.\n",
    "    - ***Klassierung 2.3***: Klassierung der durch Borderline SMOTE modifizierten Testdaten.\n",
    "    - ***Auswertung 2.3***: Auswertungen der Ergebnisse mittels verschiedener Bewertungskennzahlen und -methoden, welche sich aus der Konfusionsmatrix ableiten lassen.\n",
    "    - ***Training 2.4***: Training verschiedener Algorithmen mit durch ADASYN modifizierten Trainingsdaten für das binäre Klassifikationsproblem.\n",
    "    - ***Klassierung 2.4***: Klassierung der durch ADASYN modifizierten Testdaten.\n",
    "    - ***Auswertung 2.4***: Auswertungen der Ergebnisse mittels verschiedener Bewertungskennzahlen und -methoden, welche sich aus der Konfusionsmatrix ableiten lassen.\n",
    "    - ***Experimente***: Austesten von Kombinationen verschiedener Techniken zur Datenmodifikation.\n",
    "    - ***Datenmodifikation 3.1***: Der Trainingsdatensatz wird in vier gleich große Teile aufgespalten. Jeder der Teile wird von unterschiedlichen Oversampling-Algorithmen ausbalanciert. Nach Oversampling werden die vier Datensätze wieder zu einem einzigen zusammengefügt.\n",
    "    - ***Training 3.1***: Training verschiedener Algorithmen mit modifizierten Trainingsdaten für das binäre Klassifikationsproblem.\n",
    "    - ***Klassierung 3.1***: Klassierung der modifizierten Testdaten.\n",
    "    - ***Auswertung 3.1***: Auswertungen der Ergebnisse mittels verschiedener Bewertungskennzahlen und -methoden, welche sich aus der Konfusionsmatrix ableiten lassen.\n",
    "    - ***Datenmodifikation 3.2***: Der Trainingsdatensatz wird gestaffelt von vier verschiedenen Oversampling-Algorithmen ausbalanciert. Nach und nach wird ein Verhältnis von zuerst 1:4 bis hin zu 4:4 zwischen den zwei Klassen des binären Klassifikationsproblems hergestellt.\n",
    "    - ***Training 3.2***: Training verschiedener Algorithmen mit modifizierten Trainingsdaten für das binäre Klassifikationsproblem.\n",
    "    - ***Klassierung 3.2***: Klassierung der modifizierten Testdaten.\n",
    "    - ***Auswertung 3.2***: Auswertungen der Ergebnisse mittels verschiedener Bewertungskennzahlen und -methoden, welche sich aus der Konfusionsmatrix ableiten lassen.\n",
    "\n",
    "Für eine Interpretation der Ergebnisse seien Leser:innen auf die Bachelorarbeit verwiesen."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Initialisierung\n",
    "In diesem Kapitel werden Einstellungen und Importierungen für nachfolgende Kapitel des Notebooks vorgenommen und der mit Klassenzuordnungen versehene Datensatz `ccf_train` (csv Datei) wird in einer Variable abgespeichert."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Importieren aller benötigten Module und Funktionen"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualisierung der Diagramme direkt im Notebook.\n",
    "%matplotlib inline\n",
    "# Importieren des Moduls matplotlib unter dem Namen mpl um Parameter für die Visualisierung festzulegen.\n",
    "import matplotlib as mpl\n",
    "# Importieren des Moduls matplotlib.pyplot zur Visualisierung.\n",
    "import matplotlib.pyplot as plt\n",
    "# Benötigte Importierungen der Module numpy und os.\n",
    "import numpy as np\n",
    "# Importieren des Moduls os um Zugriff auf das Festplattenverzeichnis zu erlangen.\n",
    "import os\n",
    "# Importieren der Funkion scatter_matrix aus dem Modul pandas.plotting zur Visualisierung von ccf_data in Streudiagrammen.\n",
    "from pandas.plotting import scatter_matrix\n",
    "# Importieren der Funktion train_test_split aus dem Modul sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Importieren des KNeighborsClassifier aus dem Modul sklearn.neighbors .\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Importieren der Funktion DecisionTreeClassifier aus dem Modul sklearn.tree .\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Importieren der Funktion RandomForestClassifier aus dem Modul sklearn.ensemble .\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Importieren der Funktion GaussianNB aus dem Modul sklearn.naive_bayes .\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Importieren von Seaborn zur Visualisierung der Konfusionsmatrix\n",
    "import seaborn as sns\n",
    "# Importieren der Funktionen roc_curve, roc_auc_score und precision_recall_curve, average_precision_score aus dem Modul sklearn.metrics zur Erstellung der ROC und PR Kurve sowie zur Berechnung des Flächeninhalts AUROC und dem gewichteten Mittelwert der Werte für precision an jedem Punkt der PR-Kurve.\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, average_precision_score\n",
    "# Importieren der Funktion confusion_matrix aus dem Modul sklearn.metrics .\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# Importieren des Moduls pandas um das Auslesen der csv Datei zu ermöglichen.\n",
    "import pandas as pd\n",
    "\n",
    "# Importieren des Moduls pySMOTE für SMOTE mit der Interpolationsvariante Rechteck\n",
    "import pySMOTE\n",
    "# Importieren des RandomOversampler aus der Softwarebibliothek imblearn.oversampling\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "# Importieren von SMOTE aus der Softwarebibliothek imblearn.oversampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "# Importieren von BorderlineSMOTE aus der Softwarebibliothek imblearn.oversampling\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "# Importieren von ADASYN aus der Softwarebibliothek imblearn.oversampling\n",
    "from imblearn.over_sampling import ADASYN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In diesem Abschnitt werden verschiedene Funktionen für die nachfolgenden Notebook Abschnitte definiert."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Funktion zur Abspeicherung von Bildern.\n",
    "# fig_id legt den Namen des abgespeicherten Bildes fest.\n",
    "# tight_layout passt automatisch die Größe mehrerer untergeordneter Graphen an, damit diese alle im Gesamtgebiet des übergeordneten Graphen liegen.\n",
    "# fig_extension legt den Datentyp des abgespeicherten Bildes fest.\n",
    "# resolution bestimmt die Auflösung des Bildes.\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Funktion, um das Auslesen einer csv Dateien zu ermöglichen."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Abspeichern des Pfades, unter welchem der Datensatz des Wettbewerbs abgespeichert ist.\n",
    "CCF_PATH = os.path.join(\"datasets\", \"ccf\")\n",
    "\n",
    "# Definition der Funktion load_ccf_data.\n",
    "def load_ccf_data(ccf_path=CCF_PATH):\n",
    "    # Abspeichern des Pfades, unter welchem der Datensatz ccf_test abgespeichert ist, in der Variable csv_path.\n",
    "    csv_path = os.path.join(ccf_path, \"ccf.csv\")\n",
    "    # Auslesen der Daten in der csv Datei mit Hilfe von pandas. Abspeicherung in der Variablen data.\n",
    "    # Merkmalsausprägungen, welche in dem Datensatz fehlen, wurden durch den Wert -1 ersetzt. Diese Stellen werden im Folgenden durch den Ausdruck NaN (Not a Number) ausgetauscht.\n",
    "    data = pd.read_csv(csv_path)\n",
    "    # Rückgabe des vollständigen Datensatzes.\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Funktion um sechs verschiedene Klassifikatoren zu initialisieren. Für diese Funktionen werden Standardparameter definiert, wie beispielsweise 'neighbors' , 'estimators' und 'leafs', welche die Klassifikatoren individuell beeinflussen. Diese können abgeändert werden, sofern eine Umstellung der Klassifikatoren erwünscht ist."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Funktion welche eine Liste von initialisierten Klassifikatoren zurückgibt\n",
    "def create_classifiers(neighbors=5, jobs=-1, random=42, estimators=10, leafs=16):\n",
    "\n",
    "    classifier_list= [# Initialisieren des KNeighborsClassifier.\n",
    "                      # n_neighbors=5 bedeutet, dass für die Klassierung eines Punktes die Information von 5 Nachbarn beachtet wird.\n",
    "                      # n_jobs=-1 bedeutet, dass für die Berechnungen alle Kerne des CPU genutzt werden (-> schneller).\n",
    "                      KNeighborsClassifier(n_neighbors=neighbors, n_jobs=jobs),\n",
    "                      # Initialisieren des DecisionTreeClassifier mit dem Blatt-Aufspaltungskriterium 'gini' und dem random_state=42 um reproduzierbare Ergebnisse zu ermöglichen.\n",
    "                      DecisionTreeClassifier(criterion='gini', random_state=random),\n",
    "                      # Initialisieren des DecisionTreeClassifier mit dem Blatt-Aufspaltungskriterium 'entropy' und dem random_state=42 um reproduzierbare Ergebnisse zu ermöglichen.\n",
    "                      DecisionTreeClassifier(criterion='entropy', random_state=random),\n",
    "                      # Initialisieren eines RandomForestClassifier.\n",
    "                      # n_estimators=10 bedeutet, dass 10 Bäume erzeugt werden, welche das Voting übernehmen.\n",
    "                      # max_leaf_nodes=16 bedeutet, dass ein einzelner Baum der erzeugt wird, maximal 16 Blattknoten besitzen darf.\n",
    "                      # Festlegen des random_state auf 42 damit das Ergebnis reproduzierbar bleibt.\n",
    "                      # n_jobs=-1 bedeutet, dass für die Berechnungen alle Kerne des CPU genutzt werden (-> schneller).\n",
    "                      # criterion='entropy' legt Gini als Kriterium zur Aufspaltung der Knoten in den Entscheidungsbäumen fest.\n",
    "                      RandomForestClassifier(n_estimators=estimators, max_leaf_nodes=leafs, random_state=random, n_jobs=jobs, criterion='gini'),\n",
    "                      # Initialisieren eines RandomForestClassifier.\n",
    "                      # n_estimators=10 bedeutet, dass 10 Bäume erzeugt werden, welche das Voting übernehmen.\n",
    "                      # max_leaf_nodes=16 bedeutet dass ein einzelner Baum der erzeugt wird, maximal 16 Blattknoten besitzen darf.\n",
    "                      # Festlegen des random_state auf 42 damit das Ergebnis reproduzierbar bleibt.\n",
    "                      # n_jobs=-1 bedeutet, dass für die Berechnungen alle Kerne des CPU genutzt werden (-> schneller).\n",
    "                      # criterion='entropy' legt die Entropie als Kriterium zur Aufspaltung der Knoten in den Entscheidungsbäumen fest.\n",
    "                      RandomForestClassifier(n_estimators=estimators, max_leaf_nodes=leafs, random_state=random, n_jobs=jobs, criterion='entropy'),\n",
    "                      # Initialisieren eines Gaussian Naive Bayes.\n",
    "                      GaussianNB()\n",
    "                      ]\n",
    "    \n",
    "    # Rückgabe der Liste an Klassifikatoren\n",
    "    return classifier_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Funktion, um die in einer Liste abgespeicherten Klassifikatoren mit einem Trainingsdatensatz (bestehend aus den Attributsausprägungen 'train_features' und den Klassenzuordnungen 'train_labels') zu trainieren."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Funktion zum Trainieren von Klassifikatoren mit Trainingsdaten.\n",
    "# Die Trainingsdaten bestehen dabei aus den Features train_features und den Klassenzuordnungen train_labels.\n",
    "# In classifier_list sind die am Training teilnehmenden Klassifikatoren abgespeichert.\n",
    "def train_models(train_features, train_labels, classifier_list):\n",
    "    # Iterieren über die Liste der am Training teilnehmenden Klassifikatoren\n",
    "    for classifier in classifier_list:\n",
    "        # Training des aktuell ausgewählten Klassifikators mit den Trainingsdaten train_features und train_labels\n",
    "        classifier.fit(train_features, train_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Funktion um mit den trainierten Klassifikatoren einen Testdatensatz zu klassieren. Die Funktion gibt sowohl eindeutige Zuordnungen ('predictions'), als auch Wahrscheinlichkeiten für die Zuordnung zu einer Klasse ('prediction_probas') zurück."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Funktion zur Klassierung von Testdaten durch verschiedene Klassifikatoren.\n",
    "def klassieren(test_features, classifier_list):\n",
    "    # Anlegen zweier Listen. predictions speichert dabei die Klassierungen der Klassifikatoren aus der classifier_list ab. prediction_probas speichert die Wahrscheinlichkeiten für eine Klassenzugehörigkeit ab, welche die Klassifikatoren aus der classifier_list für einen Datenpunkt aus den Testdaten berechnet haben.\n",
    "    predictions=[]\n",
    "    prediction_probas=[]\n",
    "    # Iterieren über die Klassifikatoren aus der classifier_list.\n",
    "    for classifier in classifier_list:\n",
    "        # Klassierung der Testdaten.\n",
    "        predictions.append(classifier.predict(test_features))\n",
    "        # Berechnung der Wahrscheinlichkeit für eine Klassenzuordnung.\n",
    "        prediction_probas.append((classifier.predict_proba(test_features)))\n",
    "    # Rückgabe der Klassierungen und Wahrscheinlichkeiten für eine Klassenzuordnung.\n",
    "    return predictions, prediction_probas"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Funktion zur Erstellung einer Konfusionsmatrix. Diese wurde übernommen aus dem folgenden GitHub repository: <https://github.com/DTrimarchi10/confusion_matrix/blob/master/cf_matrix.py>\n",
    "Um die Ausgabe der Matrix mit der Verwendung in der Bachelorarbeit konsistent zu halten, wurden die Klassen 0 und 1 vertauscht. Zudem wurden die TN-Rate als Bewertungskennzahl hinzugefügt, die Größe der Abbildung abgeändert, zwei Parameter der Funktion abgeändert und die Kommentare auf Deutsch übersetzt."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def make_confusion_matrix(cf,\n",
    "                          group_names=None,\n",
    "                          count=True,\n",
    "                          percent=True,\n",
    "                          cbar=True,\n",
    "                          xyticks=True,\n",
    "                          xyplotlabels=True,\n",
    "                          sum_stats=True,\n",
    "                          figsize=None,\n",
    "                          cmap='Blues',\n",
    "                          title=None):\n",
    "    '''\n",
    "    This function will make a pretty plot of an sklearn Confusion Matrix cm using a Seaborn heatmap visualization.  #####Deutsch: Diese Funktion erzeugt eine schöne grafische Darstellung einer sklearn Konfusionsmatrix mit der Hilfe der Seaborn-Heatmap.\n",
    "    Arguments                                                                                                       #####Deutsch: Parameter\n",
    "    ---------\n",
    "    cf:            confusion matrix to be passed in                                                                 #####Deutsch: Konfusionsmatrix, die übergeben werden muss.\n",
    "    group_names:   List of strings that represent the labels row by row to be shown in each square.                 #####Deutsch: Liste von Elementen des Datentyps String, welche die Klassenzuordnungen Zeile für Zeile repräsentieren, die in der Matrix angezeigt                                                                                                                               werden sollen.\n",
    "    categories:    List of strings containing the categories to be displayed on the x,y axis. Default is 'auto'     #####Deutsch: Liste von Elementen des Datentyps String, welche die Kategorien enthält, die auf der x- und der y-Achse angezeigt werden sollen.\n",
    "    count:         If True, show the raw number in the confusion matrix. Default is True.                           #####Deutsch: Falls True, wird die absolute Häufigkeit in den Feldern der Konfusionsmatrix angezeigt. Die Standardeinstellung ist True.\n",
    "    percent:       If True, show the proportions for each category. Default is True.                                #####Deutsch: Falls True, werden die relativen Häufigkeiten der vier Kategorien im Verhältnis zum gesamten Datensatz angezeigt. Die                                                                                                                                             Standardeinstellung ist True.\n",
    "    cbar:          If True, show the color bar. The cbar values are based off the values in the confusion matrix.   #####Deutsch: Falls True, wird eine Farblegende für den Farbverlauf der einzelnen Felder angezeigt. Die Standardeinstellung ist True.\n",
    "                   Default is True.\n",
    "    xyticks:       If True, show x and y ticks. Default is True.                                                    #####Deutsch: Falls True, werden die Felder der Heatmap mit den Klassenzugehörigkeiten beschriftet. Die Standardeinstellung ist True.\n",
    "    xyplotlabels:  If True, show 'True Label' and 'Predicted Label' on the figure. Default is True.                 #####Deutsch: Falls True, werden die übergeordneten Beschriftungen 'Tatsächliche Klassenzuordnung' und 'Vorhergesagte Klassenzuordnung' angezeigt.                                                                                                                              Die Standardeinstellung ist True.\n",
    "    sum_stats:     If True, display summary statistics below the figure. Default is True.                           #####Deutsch: Falls True, werden unter der Heatmap einige Bewertungskennzahlen angezeigt. Die Standardeinstellung ist True.\n",
    "    figsize:       Tuple representing the figure size. Default will be the matplotlib rcParams value.               #####Deutsch: Tupel, welches die Abbildungsgröße festlegt. Die Standardeinstellungen sind die matplotlib rcParams Werte.\n",
    "    cmap:          Colormap of the values displayed from matplotlib.pyplot.cm. Default is 'Blues'                   #####Deutsch: Farbzuordnung der Werte die von matplotlib.pyplot.cm. angezeigt werden. Die Standardeinstellung ist 'Blues' (deutsch: Blautöne).\n",
    "                   See http://matplotlib.org/examples/color/colormaps_reference.html                                              Referenz zur matplotlib colormap: http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "\n",
    "    title:         Title for the heatmap. Default is None.                                                          #####Deutsch: Titel der Heatmap. Standardmäßig gibt es keinen Titel.\n",
    "    '''\n",
    "\n",
    "    # Vertauschen der Klassen für die Konsistenz der Konfusionsmatrix mit der restlichen Bachelorarbeit\n",
    "    e00 = cf[0][0]\n",
    "    e01 = cf[0][1]\n",
    "    e10 = cf[1][0]\n",
    "    e11 = cf[1][1]\n",
    "\n",
    "    cf[0][0] = e11\n",
    "    cf[1][1] = e00\n",
    "    cf[0][1] = e10\n",
    "    cf[1][0] = e01\n",
    "\n",
    "    # CODE TO GENERATE TEXT INSIDE EACH SQUARE                                                                      #####Deutsch: Source Code, um Text in jedem Feld zu erzeugen\n",
    "    blanks = ['' for i in range(cf.size)]\n",
    "\n",
    "    if group_names and len(group_names)==cf.size:\n",
    "        group_labels = [\"{}\\n\".format(value) for value in group_names]\n",
    "    else:\n",
    "        group_labels = blanks\n",
    "\n",
    "    if count:\n",
    "        group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\n",
    "    else:\n",
    "        group_counts = blanks\n",
    "\n",
    "    if percent:\n",
    "        group_percentages = [\"{0:.2%}\".format(value) for value in cf.flatten()/np.sum(cf)]\n",
    "    else:\n",
    "        group_percentages = blanks\n",
    "\n",
    "    box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels,group_counts,group_percentages)]\n",
    "    box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])\n",
    "\n",
    "\n",
    "    # CODE TO GENERATE SUMMARY STATISTICS & TEXT FOR SUMMARY STATS                                                  #####Deutsch: Source Code, um Bewertungskennzahlen und Text dazu anzuzeigen\n",
    "    if sum_stats:\n",
    "        #Accuracy is sum of diagonal divided by total observations                                                  #####Deutsch: Die Accuracy ist die Summe der Diagonale, geteilt durch die gesamte Zahl an Datenpunkten die klassiert wurden\n",
    "        accuracy  = np.trace(cf) / float(np.sum(cf))\n",
    "\n",
    "        #if it is a binary confusion matrix, show some more stats                                                   #####Deutsch: Sofern es eine binäre Konfusionsmatrix ist, werden weitere Bewertungskennzahlen angezeigt\n",
    "        if len(cf)==2:\n",
    "            #Metrics for Binary Confusion Matrices                                                                  #####Deutsch: Bewertungskennzahlen für binäre Konfusionsmatrizen\n",
    "            precision = cf[0,0] / sum(cf[:,0])\n",
    "            recall    = cf[0,0] / sum(cf[0,:])\n",
    "            f1_score  = 2*precision*recall / (precision + recall)\n",
    "            tn_rate   = cf[1,1] / sum(cf[1,:])\n",
    "            stats_text = \"\\n\\nAccuracy={:0.3f}\\nPrecision={:0.3f}\\nTP-Rate/Recall={:0.3f}\\nTN-Rate={:0.3f}\\nF1 Score={:0.3f}\".format(\n",
    "                accuracy,precision,recall,tn_rate,f1_score)\n",
    "        else:\n",
    "            stats_text = \"\\n\\nAccuracy={:0.3f}\".format(accuracy)\n",
    "    else:\n",
    "        stats_text = \"\"\n",
    "\n",
    "\n",
    "    # SET FIGURE PARAMETERS ACCORDING TO OTHER ARGUMENTS                                                            #####Deutsch: Parameter der Abbildung gemäß den übergebenen Parametern einstellen\n",
    "    if figsize==None:\n",
    "        #Get default figure size if not set                                                                         #####Deutsch: Sofern keine Abbildungsgröße angegeben wurde, wird die Standardgröße verwendet\n",
    "        figsize = plt.rcParams.get('figure.figsize')\n",
    "\n",
    "    if xyticks==False:\n",
    "        #Do not show categories if xyticks is False                                                                 #####Deutsch: Die Matrix wird nicht mit den Klassenzugehörigkeiten beschriftet\n",
    "        categories=False\n",
    "\n",
    "\n",
    "    # MAKE THE HEATMAP VISUALIZATION                                                                                #####Deutsch: Visualisierung der Heatmap\n",
    "    plt.figure(figsize=(1.5,1.5))\n",
    "    sns.heatmap(cf,annot=box_labels,fmt=\"\",cmap=cmap,cbar=cbar,xticklabels=[1, 0],yticklabels=[1, 0])\n",
    "\n",
    "    if xyplotlabels:\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label' + stats_text)\n",
    "    else:\n",
    "        plt.xlabel(stats_text)\n",
    "\n",
    "    if title:\n",
    "        plt.title(title)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Funktion zur Auswertung der trainierten Klassifikatoren mit dem Testdatensatz."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Funktion zur Auswertung der Klassierungen und berechneten Wahrscheinlichkeiten für eine Klassenzuordnung.\n",
    "def auswerten(predictions, prediction_probas, identifier):\n",
    "\n",
    "    # Liste von Klassifikatoren, um die Graphen des Algorithmus beschriften zu können.\n",
    "    classifiers = ['K-Nearest-Neighbors', 'Decision_Tree_Gini', 'Decision_Tree_Entropy', 'Random_Forest_Gini', 'Random_Forest_Entropy', 'Gaussian_Naive_Bayes']\n",
    "\n",
    "\n",
    "    # Initialisierung eines Zählers classifier_counter um zusätzlich über die Namen aus der Liste classifier iterieren zu können.\n",
    "    classifier_counter = 0\n",
    "\n",
    "\n",
    "    # Iterieren über alle Klassierungen in der Liste predictions.\n",
    "    for prediction in predictions:\n",
    "\n",
    "        # Anzeigen der Konfusionsmatrix.\n",
    "        # Zeilen = tatsächliche Kategorien.\n",
    "        # Spalten = vorhergesagte Kategorien.\n",
    "        cf_matrix = confusion_matrix(ccf_test_labels, prediction)\n",
    "        make_confusion_matrix(cf_matrix, figsize=(2,2), cbar=False, percent=False) # Bei Bedarf kann hier die Konfusionsmatrix mit dem Namen des Klassifikators beschriftet werden. Source Code: , title=classifiers[classifier_counter]\n",
    "\n",
    "        # Einstellung der Schriftgröße\n",
    "        sns.set(font_scale=.5)\n",
    "\n",
    "        # Erzeugung eines Namens für die Konfusionsmatrix. Dieser setzt sich aus dem Klassifikator, '_Konfusionsmatrix_' und dem übergebenen identifier zusammen.\n",
    "        fig_name = classifiers[classifier_counter] + '_Konfusionsmatrix_' + identifier\n",
    "\n",
    "        # Abspeichern der Konfusionsmatrix in einem einzelnen Bild mit der im Kapitel Initialisierung definierten Funktion. Für eine verkürzte Ladezeit kann die Auflösung des Bildes in der Funktion save_fig reduziert werden.\n",
    "        save_fig(fig_name)\n",
    "\n",
    "        # Ausgabe unterdrücken\n",
    "        plt.close()\n",
    "\n",
    "        # Erhöhung des classifier_counter.\n",
    "        classifier_counter=classifier_counter+1\n",
    "\n",
    "    # Initialisierung eines Zählers classifier_counter um zusätzlich über die Namen aus der Liste classifier iterieren zu können.\n",
    "    classifier_counter = 0\n",
    "\n",
    "    # Iterieren über alle Wahrscheinlichkeiten für eine Klassenzuordnung in der Liste prediction_probas.\n",
    "    for prediction_proba in prediction_probas:\n",
    "\n",
    "        # Initialisierung der Abbildung welche aus zwei verschiedenen Grafiken besteht.\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(6,3))\n",
    "\n",
    "        #f.suptitle(classifiers[classifier_counter], fontsize=10) # Titel der Abbildung wurde auskommentiert und kann bei Bedarf durch Einkommentieren der Zeile wieder angegeben werden\n",
    "\n",
    "        # Auswahl der Wahrscheinlichkeiten, dass ein Element Klasse 1 zugeordnet wird.\n",
    "        prediction_proba = prediction_proba[:, 1]\n",
    "\n",
    "        # Berechnung und Ausgabe des Flächeninhalts AUROC.\n",
    "        auc = roc_auc_score(ccf_test_labels, prediction_proba)\n",
    "\n",
    "        # Erzeugung zweier Serien von False-Positive- und True-Positive-Rate um anschließend den ROC Graphen zeichnen zu können.\n",
    "        fpr, tpr, _ = roc_curve(ccf_test_labels, prediction_proba)\n",
    "\n",
    "        # Beschriftung des ROC Graphen mit dem Namen des Klassifikators und dem Flächeninhalt unter der Kurve.\n",
    "        label_roc = classifiers[classifier_counter] + ' (AUROC = %0.7f)'% auc\n",
    "\n",
    "        # Darstellung der ROC Kurve mit Angabe des Flächeninhalts AUROC auf 7 Nachkommastellen genau. Einzelne Klassierungsergebnisse können durch Punkte symbolisiert werden mit dem folgendem Source Code: marker='.',\n",
    "        ax1.plot(fpr, tpr, label=label_roc)\n",
    "\n",
    "        # Titel\n",
    "        ax1.set_title('ROC Plot')\n",
    "        # Axenbeschriftungen\n",
    "        ax1.set(xlabel='False Positive Rate', ylabel='True Positive Rate')\n",
    "        # Legende\n",
    "        ax1.legend()\n",
    "\n",
    "        # Erzeugung zweier Serien von Precision und Recall, um anschließend den PR Graphen zeichnen zu können\n",
    "        precision, recall, thresholds = precision_recall_curve(ccf_test_labels, prediction_proba)\n",
    "\n",
    "        # Berechnung der Average Precision (vgl. https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html).\n",
    "        precision_avg = average_precision_score(ccf_test_labels, prediction_proba)\n",
    "\n",
    "        label_pr = classifiers[classifier_counter] + ' (PR_AVG = %0.7f)'% precision_avg\n",
    "\n",
    "        # Darstellung der Precision-Recall Kurve. Einzelne Klassierungsergebnisse können durch Punkte symbolisiert werden mit dem folgendem Source Code: marker='.',\n",
    "        ax2.plot(recall, precision, label=label_pr)\n",
    "\n",
    "        # Titel\n",
    "        ax2.set_title('PR Plot')\n",
    "        # Axenbeschriftungen\n",
    "        ax2.set(xlabel='Recall', ylabel='Precision')\n",
    "        # Legende\n",
    "        ax2.legend()\n",
    "\n",
    "        # Erzeugung eines Namens für den Plot. Dieser setzt sich aus dem Klassifikator, '_ROC_PR_' und dem übergebenen identifier zusammen.\n",
    "        fig_name = classifiers[classifier_counter] + '_ROC_PR_' + identifier\n",
    "\n",
    "        # Abspeichern des PR Plot in einem einzelnen Bild mit der im Kapitel Initialisierung definierten Funktion. Für eine verkürzte Ladezeit kann die Auflösung des Bildes in der Funktion save_fig reduziert werden.\n",
    "        save_fig(fig_name)\n",
    "\n",
    "        # Einstellung damit sich die beiden Grafiken der Abbildung nicht überschneiden.\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Ausgabe unterdrücken.\n",
    "        plt.close()\n",
    "\n",
    "        # Erhöhung des classifier_counter.\n",
    "        classifier_counter=classifier_counter+1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Funktion um aus einem Datensatz (bestehend aus den Attributsausprägungen X und den Klassenzuordnungen y) alle Elemente einer Klasse herauszufiltern. In diesem Fall wird die Funktion dazu genutzt die Minderheit herauszufiltern und die Mehrheit zu entfernen."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def filter_minority(X, y, majority_class):\n",
    "\n",
    "    i=0\n",
    "    index_list=[]\n",
    "    while i<len(X):\n",
    "        if y[i]==majority_class:\n",
    "            index_list.append(i)\n",
    "        i +=1\n",
    "    print(index_list)\n",
    "    X.drop(index_list, inplace=True)\n",
    "    minority = X.to_numpy()\n",
    "\n",
    "    return minority"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Methode um die Anwendung von pySMOTE an die Verwendung der restlichen Oversampling-Methoden anzugleichen"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def smote_rectangle(X ,y, minority_class, majority_class, ratio=None, neighbors=5):\n",
    "\n",
    "    # Herausfiltern der Minderheit aus dem Trainingsdatensatz\n",
    "    ccf_train_labels_new = y.reset_index(drop=True)\n",
    "    ccf_train_prepared_new = X.reset_index(drop=True)\n",
    "    minority = filter_minority(ccf_train_prepared_new, ccf_train_labels_new, majority_class)\n",
    "\n",
    "    # Formel, um die Menge an neu zu generierenden Punkten auf eine Anzahl zu erhöhen, welche die Anteile beider Klassen im Datensatz auf 50% setzt.\n",
    "    if ratio is not None:\n",
    "        ratio=ratio\n",
    "    else:\n",
    "        ratio = int(((len(y)/len(minority)) - 1)*100)\n",
    "        subtraction = int(((len(y)/len(minority)) - 1)*100)%100\n",
    "        ratio-=subtraction\n",
    "\n",
    "    # Initialisierung und Anwendung der Funktion SMOTE aus dem Modul pySMOTE auf die Minderheit des Trainingsdatensatzes\n",
    "    smote = pySMOTE.SMOTE(ratio=ratio, k_neighbors=neighbors)\n",
    "    new_samples = smote.oversample(minority, merge=True)\n",
    "\n",
    "    # Anlegen einer Spalte für die Klassenzugehörigkeiten der neuen Datenpunkte\n",
    "    if minority_class==1:\n",
    "        label_column = pd.DataFrame(1, index=np.arange(len(new_samples)), columns=['target'])\n",
    "    else:\n",
    "        label_column = pd.DataFrame(0, index=np.arange(len(new_samples)), columns=['target'])\n",
    "\n",
    "    # Zusammenführung des alten Datensatzes mit den neu generierten Datenpunkten\n",
    "    X = X.to_numpy()\n",
    "    y = y.to_numpy()\n",
    "    label_column = label_column.to_numpy()\n",
    "    label_column = label_column.reshape(len(label_column),)\n",
    "\n",
    "\n",
    "    X_res = np.concatenate((X, new_samples))\n",
    "    y_res = np.concatenate((y, label_column))\n",
    "\n",
    "    X_res = pd.DataFrame(X_res)\n",
    "    y_res = pd.DataFrame(y_res)\n",
    "\n",
    "\n",
    "    y_res[0] = y_res[0].astype(str)\n",
    "\n",
    "\n",
    "    i=0\n",
    "    while i<len(y_res):\n",
    "        if y_res[0][i]=='1.0':\n",
    "            y_res[0][i]='1'\n",
    "        if y_res[0][i]=='0.0':\n",
    "            y_res[0][i]='0'\n",
    "        i +=1\n",
    "\n",
    "    y_res[0] = y_res[0].astype(int)\n",
    "\n",
    "    # Rückgabe des Trainingsdatensatzes, welcher nun die zusätzlich generierten Datenpunkte enthält.\n",
    "    return X_res, y_res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Einstellungen für die verschiedenen Funktionen"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Um für mehrere Durchläufe des Notebooks die gleichen Ergebnisse zu erzeugen wird der Seed des RNG festgelegt.\n",
    "np.random.seed(42)\n",
    "\n",
    "# Visualisierung der Diagramme direkt im Notebook.\n",
    "%matplotlib inline\n",
    "\n",
    "# Einstellungen für die Achsenbeschriftungen.\n",
    "mpl.rc('axes', labelsize=20)\n",
    "mpl.rc('xtick', labelsize=15)\n",
    "mpl.rc('ytick', labelsize=15)\n",
    "\n",
    "# Erstellung eines Speicherort für die Graphen\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"ccf_project\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nun wird die zuvor definierte Funktionen zum Laden der Daten genutzt und es werden die ersten fünf Datenpunkte ausgegeben."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ccf_data = load_ccf_data()\n",
    "ccf_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualisierung\n",
    "In diesem Kapitel werden einige Attribute des Datensatzes in Histogrammen visualisiert und als Bilder abgespeichert. Bei der Visualisierung des gesamten Datensatzes haben sich diese als repräsentativ herausgestellt. Die Visualisierung und Abspeicherung aller Attribute ist im Anschluss (aufgrund der langen Laufzeit) auskommentiert angegeben.\n",
    "\n",
    "Visualisierung des Histogramms des Attributs 'Time'."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ax = ccf_data['Time'].hist(bins=50)\n",
    "ax.set_xticks(ax.get_xticks()[::2])\n",
    "ax.set_xlim((0,175000))\n",
    "ax.set_title('Time', fontsize=15)\n",
    "save_fig('histo_Time')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Visualisierung des Attributs 'Amount'."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ax = ccf_data['Amount'].hist(bins=2000)\n",
    "ax.set_title('Amount', fontsize=15)\n",
    "ax.set_xlim([0,600])\n",
    "save_fig('histo_Amount')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Visualisierung des Attributs 'V13'."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ax = ccf_data['V13'].hist(bins=50)\n",
    "ax.set_title('V13', fontsize=15)\n",
    "save_fig('histo_V13')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ausgabe der Histogramme aller Attribute."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualisierung des Datensatzes ccf_data in Histogrammen mit jeweils bis zu 50 Säulen (bins=50).\n",
    "# figsize gibt die Größe der Darstellung in Zoll an.\n",
    "#ccf_data.hist(bins=50, figsize=(60,40))\n",
    "# Abspeichern der Histogramme in einem einzelnen Bild mit der im Kapitel Initialisierung definierten Funktion. Für eine verkürzte Ladezeit kann die Auflösung des Bildes in der Funktion save_fig reduziert werden.\n",
    "#save_fig(\"attribute_histogram_plots_ccf_data\")\n",
    "# Anzeigen der Histogramme mit dem Modul matplotlib.pyplot.\n",
    "#plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Analyse\n",
    "In diesem Kapitel wird der Datensatz aufgespalten, sodass Machine Learning Algorithmen einen Großteil des Datensatzes für ihr Training verwenden können. Im Anschluss sollen die Algorithmen auf einem Testdatensatz (dem übrig gebliebenen kleineren Teil) ausgewertet werden. Die Auswertung erfolgt anhand von verschiedenen Bewertungskennzahlen und -methoden. Grundlage für alle Bewertungskennzahlen und -methoden bilden dabei die absoluten Häufigkeiten in der Konfusionsmatrix. Im Anschluss an diese erste Auswertung folgen zwei weitere Trainings- und Auswertungszyklen. Vor dem zweiten Trainings- und Auswertungszyklus wird der Trainingsdatensatz mit verschiedenen Oversampling-Algorithmen modifiziert. Vor dem dritten Trainings- und Auswertungszyklus werden Kombinationen von Oversampling-Algorithmen ausprobiert."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Training 1\n",
    "In diesem Abschnitt wird die Funktion train_test_split des Moduls sklearn.model_selection genutzt, um den Datensatz in einen Trainings- und Testdatensatz aufzuspalten. Nachfolgend werden ein K-Nearest-Neighbor-Algorithmus, zwei Entscheidungsbäume, zwei Random Forests und ein Gaussian Naive Bayes mit dem Trainingsdatensatz trainiert."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Aufspalten des Datensatzes in Klassenzuordnungen und Merkmalsausprägungen."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Abspeichern der Klassenzuordnungen (ursprüngliche \"target\"-Spalte) in der Variable ccf_labels\n",
    "ccf_labels = ccf_data[\"Class\"].copy()\n",
    "# Abspeichern der Merkmalsausprägungen in der Variable ccf_prepared\n",
    "# axis=1 bedeutet, dass sich \"target\" auf eine Spalte bezieht\n",
    "ccf_prepared = ccf_data.drop(\"Class\", axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Aufspalten von Klassenzuordnungen und Merkmalsausprägungen in jeweils einen Trainings- und einen Testdatensatz. 80% des Datensatzes wird für das Training genutzt und 20% für die Auswertung. Die Datensätze werden dabei stratifiziert. Das bedeutet, dass das Verhältnis an Klassenzuordnungen im gesamten Datensatz auch in den aufgeteilten Datensätzen widergespiegelt wird."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 80% der Daten werden für den Trainingsdatensatz genutzt, 20% für den Testdatensatz (test_size=0.2).\n",
    "# Der random_state wird auf 42 festgesetzt, damit das Ergebnis reproduzierbar ist.\n",
    "# stratify=ccf_labels sorgt dafür, die Datensätze stratifiziert werden.\n",
    "ccf_train_prepared, ccf_test_prepared, ccf_train_labels, ccf_test_labels = train_test_split(ccf_prepared, ccf_labels, test_size=0.2, random_state=42, stratify=ccf_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " Nun werden in den folgenden Zellen ein K-Nearest-Neighbors Algorithmus, zwei Entscheidungsbäume, zwei Random Forests und ein Gaussian Naive Bayes mit dem Trainingsdatensatz trainiert mit dem transformierten Trainingsdatensatz trainiert."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Anlegen einer Liste von Klassifikatoren ohne den K-Nearest-Neighbor Klassifikator. Dieser sollte aufgrund von nominalen Features in den Trainingsdaten nicht genutzt werden. Abstände zwischen den Ausprägungen nominaler Features, welcher der Algorithmus zur Klassierung nutzt, sind nicht sinnvoll interpretierbar.\n",
    "classifier_list = create_classifiers()\n",
    "\n",
    "# Trainieren der Klassifikatoren mit den unveränderten Trainingsdaten.\n",
    "train_models(ccf_train_prepared, ccf_train_labels, classifier_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Klassierung 1\n",
    "In diesem Abschnitt werden die Daten im Testdatensatz durch die trainierten Algorithmen klassiert."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Klassierung und Berechnung der Wahrscheinlichkeiten für eine Klassenzuordnung für den Testdatensatz.\n",
    "predictions, prediction_probas = klassieren(ccf_test_prepared, classifier_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Auswertung 1\n",
    "In diesem Abschnitt werden die Klassierungen der Klassifikatoren mit verschiedenen Bewertungskennzahlen und -methoden ausgewertet und die Abbildungen der Auswertung abgespeichert."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Auswertung der Klassierungen und berechneten Wahrscheinlichkeiten für eine Klassenzuordnung.\n",
    "auswerten(predictions, prediction_probas, '1')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Die Bilder können hier in der nachfolgenden Markdown-Zelle oder im Unterordner images/ccf_project/ am Speicherort des Source Codes begutachtet werden. Gleiches gilt für die nachfolgenden Markdown-Zellen, welche auf eine Auswertungszelle folgen."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![K-Nearest-Neighbors_Konfusionsmatrix](images/ccf_project/K-Nearest-Neighbors_Konfusionsmatrix_1.png)![Decision_Tree_Gini_Konfusionsmatrix](images/ccf_project/Decision_Tree_Gini_Konfusionsmatrix_1.png) ![Decision_Tree_Entropy_Konfusionsmatrix](images/ccf_project/Decision_Tree_Entropy_Konfusionsmatrix_1.png)\n",
    "![Random_Forest_Gini_Konfusionsmatrix](images/ccf_project/Random_Forest_Gini_Konfusionsmatrix_1.png)![Random_Forest_Entropy_Konfusionsmatrix](images/ccf_project/Random_Forest_Entropy_Konfusionsmatrix_1.png)![Gaussian_Naive_Bayes_Konfusionsmatrix](images/ccf_project/Gaussian_Naive_Bayes_Konfusionsmatrix_1.png)\n",
    "\n",
    "![K-Nearest-Neighbors_ROC_PR](images/ccf_project/K-Nearest-Neighbors_ROC_PR_1.png)\n",
    "![Decision_Tree_Gini_ROC_PR](images/ccf_project/Decision_Tree_Gini_ROC_PR_1.png)\n",
    "![Decision_Tree_Entropy_ROC_PR](images/ccf_project/Decision_Tree_Entropy_ROC_PR_1.png)\n",
    "![Random_Forest_Gini_ROC_PR](images/ccf_project/Random_Forest_Gini_ROC_PR_1.png)\n",
    "![Random_Forest_Entropy_ROC_PR](images/ccf_project/Random_Forest_Entropy_ROC_PR_1.png)\n",
    "![Gaussian_Naive_Bayes_ROC_PR](images/ccf_project/Gaussian_Naive_Bayes_ROC_PR_1.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Datenmodifikation 2\n",
    "In diesem Abschnitt werden auf die Datensätze Oversampling Methoden angewandt. Eine Illustration der Oversampling-Methoden mit den Auswirkungen auf die Entscheidungsregionen der hier ebenfalls verwendeten Klassifikatoren ist im Notebook 'Bsp_Oversampling(ROS, SMOTE, BSM, ADA)' zu finden. Die Abbildungen der Auswertung werden mit der Endung '_2*' abgespeichert. * steht hierbei für die konkrete Oversampling-Methode in der Versuchsreihe. Die Reihenfolge ist: ROS, SMOTE_Rechteck, SMOTE_Linie, Borderline_SMOTE, ADASYN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Der Random Oversampler wird auf den transformierten Datensatz angewandt."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Festlegen des random_state auf 42 damit das Ergebnis reproduzierbar bleibt.\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "# Resampling der Trainingsdaten (also Features und Labels)\n",
    "ccf_train_prepared_ros, ccf_train_labels_ros = ros.fit_resample(ccf_train_prepared, ccf_train_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Anwendung von SMOTE mit der Interpolationsmethode Rechteck. Hierbei werden die neuen Datenpunkte in einem Rechteck generiert, welches von den zwei erzeugenden Datenpunkten aufgespannt wird. Eine Illustration ist im Notebook 'Erzeugung_Datenpunkt_SMOTE_Rechteck' zu finden."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ccf_train_prepared_sm_rectangle, ccf_train_labels_sm_rectangle = smote_rectangle(ccf_train_prepared, ccf_train_labels, 1, 0)\n",
    "\n",
    "ccf_train_labels_sm_rectangle = ccf_train_labels_sm_rectangle.values.ravel()\n",
    "ccf_train_prepared_sm_rectangle_np = ccf_train_prepared_sm_rectangle.to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "SMOTE mit der Interpolationsmethode Linie wird auf den transformierten Datensatz angewandt. Hierbei werden die neuen Datenpunkte auf einer Verbindungslinie zwischen zwei erzeugenden Datenpunkten generiert. Eine Illustration ist im Notebook 'Erzeugung_Datenpunkt_SMOTE_Linie' zu finden."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Festlegen des random_state auf 42 damit das Ergebnis reproduzierbar bleibt. n_jobs=-1 bedeutet, dass für die Berechnungen alle Kerne des CPU genutzt werden (--> schneller). Sonst werden die Standardparameter genutzt.\n",
    "sm = SMOTE(random_state=42, n_jobs=-1)\n",
    "\n",
    "# Resampling der Trainingsdaten (also Features und Labels)\n",
    "ccf_train_prepared_sm, ccf_train_labels_sm = sm.fit_resample(ccf_train_prepared, ccf_train_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Borderline SMOTE wird auf den transformierten Datensatz angewandt."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# Festlegen des random_state auf 42 damit das Ergebnis reproduzierbar bleibt. n_jobs=-1 bedeutet, dass für die Berechnungen alle Kerne des CPU genutzt werden (--> schneller). Sonst werden die Standardparameter genutzt.\n",
    "bsm = BorderlineSMOTE(random_state=42, n_jobs=-1)\n",
    "\n",
    "# Resampling der Trainingsdaten (also Features und Labels)\n",
    "ccf_train_prepared_bsm, ccf_train_labels_bsm = bsm.fit_resample(ccf_train_prepared, ccf_train_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "ADASYN wird auf den transformierten Datensatz angewandt."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# Festlegen des random_state auf 42 damit das Ergebnis reproduzierbar bleibt. n_jobs=-1 bedeutet, dass für die Berechnungen alle Kerne des CPU genutzt werden (--> schneller). Sonst werden die Standardparameter genutzt.\n",
    "ada = ADASYN(random_state=42, n_jobs=-1)\n",
    "\n",
    "# Resampling der Trainingsdaten (also Features und Labels)\n",
    "ccf_train_prepared_ada, ccf_train_labels_ada = ada.fit_resample(ccf_train_prepared, ccf_train_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Training 2.1\n",
    "\n",
    "Die Klassifikatoren werden mit den durch Random Oversampling balancierten Trainingsdaten trainiert."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# Anlegen einer Liste von Klassifikatoren.\n",
    "classifier_list_ros = create_classifiers()\n",
    "\n",
    "# Trainieren der Klassifikatoren mit den durch Random Oversampling ausbalancierten Trainingsdaten.\n",
    "train_models(ccf_train_prepared_ros, ccf_train_labels_ros, classifier_list_ros)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Klassierung 2.1\n",
    "In diesem Abschnitt werden die Daten im Testdatensatz durch die trainierten Algorithmen klassiert."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# Klassierung und Berechnung der Wahrscheinlichkeiten für eine Klassenzuordnung für den Testdatensatz.\n",
    "predictions_ros, prediction_probas_ros = klassieren(ccf_test_prepared, classifier_list_ros)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Auswertung 2.1\n",
    "In diesem Abschnitt werden die Klassierungen der Klassifikatoren mit verschiedenen Bewertungskennzahlen und -methoden ausgewertet."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure K-Nearest-Neighbors_Konfusionsmatrix_no_label_21\n",
      "Saving figure Decision_Tree_Gini_Konfusionsmatrix_no_label_21\n",
      "Saving figure Decision_Tree_Entropy_Konfusionsmatrix_no_label_21\n",
      "Saving figure Random_Forest_Gini_Konfusionsmatrix_no_label_21\n",
      "Saving figure Random_Forest_Entropy_Konfusionsmatrix_no_label_21\n",
      "Saving figure Gaussian_Naive_Bayes_Konfusionsmatrix_no_label_21\n",
      "Saving figure K-Nearest-Neighbors_ROC_PR_21\n",
      "Saving figure Decision_Tree_Gini_ROC_PR_21\n",
      "Saving figure Decision_Tree_Entropy_ROC_PR_21\n",
      "Saving figure Random_Forest_Gini_ROC_PR_21\n",
      "Saving figure Random_Forest_Entropy_ROC_PR_21\n",
      "Saving figure Gaussian_Naive_Bayes_ROC_PR_21\n"
     ]
    }
   ],
   "source": [
    "# Auswertung der Klassierungen und berechneten Wahrscheinlichkeiten für eine Klassenzuordnung.\n",
    "auswerten(predictions_ros, prediction_probas_ros, '21')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![K-Nearest-Neighbors_Konfusionsmatrix](images/ccf_project/K-Nearest-Neighbors_Konfusionsmatrix_21.png)![Decision_Tree_Gini_Konfusionsmatrix](images/ccf_project/Decision_Tree_Gini_Konfusionsmatrix_21.png) ![Decision_Tree_Entropy_Konfusionsmatrix](images/ccf_project/Decision_Tree_Entropy_Konfusionsmatrix_21.png)\n",
    "![Random_Forest_Gini_Konfusionsmatrix](images/ccf_project/Random_Forest_Gini_Konfusionsmatrix_21.png)![Random_Forest_Entropy_Konfusionsmatrix](images/ccf_project/Random_Forest_Entropy_Konfusionsmatrix_21.png)![Gaussian_Naive_Bayes_Konfusionsmatrix](images/ccf_project/Gaussian_Naive_Bayes_Konfusionsmatrix_21.png)\n",
    "\n",
    "![K-Nearest-Neighbors_ROC_PR](images/ccf_project/K-Nearest-Neighbors_ROC_PR_21.png)\n",
    "![Decision_Tree_Gini_ROC_PR](images/ccf_project/Decision_Tree_Gini_ROC_PR_21.png)\n",
    "![Decision_Tree_Entropy_ROC_PR](images/ccf_project/Decision_Tree_Entropy_ROC_PR_21.png)\n",
    "![Random_Forest_Gini_ROC_PR](images/ccf_project/Random_Forest_Gini_ROC_PR_21.png)\n",
    "![Random_Forest_Entropy_ROC_PR](images/ccf_project/Random_Forest_Entropy_ROC_PR_21.png)\n",
    "![Gaussian_Naive_Bayes_ROC_PR](images/ccf_project/Gaussian_Naive_Bayes_ROC_PR_21.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Training 2.2.1\n",
    "Die Klassifikatoren werden mit den durch SMOTE (mit der Interpolationsmethode Rechteck) balancierten Trainingsdaten trainiert."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Abändern der Datei, damit ein Training der Klassifikatoren mit dem Datensatz möglich ist."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "                 Time        V1        V2        V3        V4        V5  \\\n0       161919.000000  1.946747 -0.752526 -1.355130 -0.661630  1.502822   \n1       124477.000000  2.035149 -0.048880 -3.058693  0.247945  2.943487   \n2        41191.000000 -0.991920  0.603193  0.711976 -0.992425 -0.825838   \n3       132624.000000  2.285718 -1.500239 -0.747565 -1.668119 -1.394143   \n4        59359.000000 -0.448747 -1.011440  0.115903 -3.454854  0.715771   \n...               ...       ...       ...       ...       ...       ...   \n455572   75873.939443 -4.930043  3.558245 -5.473387  4.158237 -3.721618   \n455573   76192.317934 -4.894591  3.466376 -5.912253  4.106286 -3.862455   \n455574   76444.158143 -5.566804  3.452522 -5.388863  4.208595 -4.599254   \n455575   76244.183256 -4.994159  3.467464 -6.173283  4.212092 -4.382754   \n455576   76372.773188 -5.781734  3.486044 -6.375878  4.272748 -4.997231   \n\n              V6        V7        V8        V9  ...       V20       V21  \\\n0       4.024933 -1.479661  1.139880  1.406819  ... -0.134435  0.076197   \n1       3.298697 -0.002192  0.674782  0.045826  ... -0.227279  0.038628   \n2       1.956261 -2.212603 -5.037523  0.000772  ...  1.280856 -2.798352   \n3      -0.350339 -1.427984  0.010010 -1.118447  ... -0.490642 -0.139670   \n4      -0.147490  0.504347 -0.113817 -0.044782  ... -0.275297 -0.243245   \n...          ...       ...       ...       ...  ...       ...       ...   \n455572 -1.923633 -5.085494  2.058408 -2.920237  ...  0.335468  1.147500   \n455573 -1.487225 -5.131383  2.001997 -3.002968  ... -0.052963  1.066442   \n455574 -1.921424 -5.089843  2.042049 -2.948916  ...  0.337925  1.036715   \n455575 -1.567384 -5.102434  2.010375 -3.026769  ...  0.138840  0.980981   \n455576 -1.808883 -4.950264  2.211178 -3.472407  ...  0.064922  1.168897   \n\n             V22       V23       V24       V25       V26       V27       V28  \\\n0       0.297537  0.307915  0.690980 -0.350316 -0.388907  0.077641 -0.032248   \n1       0.228197  0.035542  0.707090  0.512885 -0.471198  0.002520 -0.069002   \n2       0.109526 -0.436530 -0.932803  0.826684  0.913773  0.038049  0.185340   \n3       0.077013  0.208310 -0.538236 -0.278032 -0.162068  0.018045 -0.063005   \n4      -0.173298 -0.006692 -1.362383 -0.292234 -0.144622 -0.032580 -0.064194   \n...          ...       ...       ...       ...       ...       ...       ...   \n455572  0.171552 -0.359598  0.144371  0.317310 -0.190863  0.302258  0.725572   \n455573  0.285885 -0.353415  0.183828  0.088956 -0.353605 -0.105220  0.469100   \n455574  0.046358 -0.363709  0.187713  0.154247 -0.334710 -0.110793  0.484499   \n455575 -0.403597 -0.354424  0.149215  0.149957 -0.372540 -0.033387  0.820844   \n455576  0.094487 -0.849056  0.205243  0.074032 -0.227934 -0.071793  0.482801   \n\n            Amount  \n0         7.320000  \n1         2.990000  \n2       175.100000  \n3         6.100000  \n4        86.100000  \n...            ...  \n455572   99.855210  \n455573  167.547942  \n455574  135.718613  \n455575  100.721635  \n455576  254.152225  \n\n[455577 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V20</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>161919.000000</td>\n      <td>1.946747</td>\n      <td>-0.752526</td>\n      <td>-1.355130</td>\n      <td>-0.661630</td>\n      <td>1.502822</td>\n      <td>4.024933</td>\n      <td>-1.479661</td>\n      <td>1.139880</td>\n      <td>1.406819</td>\n      <td>...</td>\n      <td>-0.134435</td>\n      <td>0.076197</td>\n      <td>0.297537</td>\n      <td>0.307915</td>\n      <td>0.690980</td>\n      <td>-0.350316</td>\n      <td>-0.388907</td>\n      <td>0.077641</td>\n      <td>-0.032248</td>\n      <td>7.320000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>124477.000000</td>\n      <td>2.035149</td>\n      <td>-0.048880</td>\n      <td>-3.058693</td>\n      <td>0.247945</td>\n      <td>2.943487</td>\n      <td>3.298697</td>\n      <td>-0.002192</td>\n      <td>0.674782</td>\n      <td>0.045826</td>\n      <td>...</td>\n      <td>-0.227279</td>\n      <td>0.038628</td>\n      <td>0.228197</td>\n      <td>0.035542</td>\n      <td>0.707090</td>\n      <td>0.512885</td>\n      <td>-0.471198</td>\n      <td>0.002520</td>\n      <td>-0.069002</td>\n      <td>2.990000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>41191.000000</td>\n      <td>-0.991920</td>\n      <td>0.603193</td>\n      <td>0.711976</td>\n      <td>-0.992425</td>\n      <td>-0.825838</td>\n      <td>1.956261</td>\n      <td>-2.212603</td>\n      <td>-5.037523</td>\n      <td>0.000772</td>\n      <td>...</td>\n      <td>1.280856</td>\n      <td>-2.798352</td>\n      <td>0.109526</td>\n      <td>-0.436530</td>\n      <td>-0.932803</td>\n      <td>0.826684</td>\n      <td>0.913773</td>\n      <td>0.038049</td>\n      <td>0.185340</td>\n      <td>175.100000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>132624.000000</td>\n      <td>2.285718</td>\n      <td>-1.500239</td>\n      <td>-0.747565</td>\n      <td>-1.668119</td>\n      <td>-1.394143</td>\n      <td>-0.350339</td>\n      <td>-1.427984</td>\n      <td>0.010010</td>\n      <td>-1.118447</td>\n      <td>...</td>\n      <td>-0.490642</td>\n      <td>-0.139670</td>\n      <td>0.077013</td>\n      <td>0.208310</td>\n      <td>-0.538236</td>\n      <td>-0.278032</td>\n      <td>-0.162068</td>\n      <td>0.018045</td>\n      <td>-0.063005</td>\n      <td>6.100000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>59359.000000</td>\n      <td>-0.448747</td>\n      <td>-1.011440</td>\n      <td>0.115903</td>\n      <td>-3.454854</td>\n      <td>0.715771</td>\n      <td>-0.147490</td>\n      <td>0.504347</td>\n      <td>-0.113817</td>\n      <td>-0.044782</td>\n      <td>...</td>\n      <td>-0.275297</td>\n      <td>-0.243245</td>\n      <td>-0.173298</td>\n      <td>-0.006692</td>\n      <td>-1.362383</td>\n      <td>-0.292234</td>\n      <td>-0.144622</td>\n      <td>-0.032580</td>\n      <td>-0.064194</td>\n      <td>86.100000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>455572</th>\n      <td>75873.939443</td>\n      <td>-4.930043</td>\n      <td>3.558245</td>\n      <td>-5.473387</td>\n      <td>4.158237</td>\n      <td>-3.721618</td>\n      <td>-1.923633</td>\n      <td>-5.085494</td>\n      <td>2.058408</td>\n      <td>-2.920237</td>\n      <td>...</td>\n      <td>0.335468</td>\n      <td>1.147500</td>\n      <td>0.171552</td>\n      <td>-0.359598</td>\n      <td>0.144371</td>\n      <td>0.317310</td>\n      <td>-0.190863</td>\n      <td>0.302258</td>\n      <td>0.725572</td>\n      <td>99.855210</td>\n    </tr>\n    <tr>\n      <th>455573</th>\n      <td>76192.317934</td>\n      <td>-4.894591</td>\n      <td>3.466376</td>\n      <td>-5.912253</td>\n      <td>4.106286</td>\n      <td>-3.862455</td>\n      <td>-1.487225</td>\n      <td>-5.131383</td>\n      <td>2.001997</td>\n      <td>-3.002968</td>\n      <td>...</td>\n      <td>-0.052963</td>\n      <td>1.066442</td>\n      <td>0.285885</td>\n      <td>-0.353415</td>\n      <td>0.183828</td>\n      <td>0.088956</td>\n      <td>-0.353605</td>\n      <td>-0.105220</td>\n      <td>0.469100</td>\n      <td>167.547942</td>\n    </tr>\n    <tr>\n      <th>455574</th>\n      <td>76444.158143</td>\n      <td>-5.566804</td>\n      <td>3.452522</td>\n      <td>-5.388863</td>\n      <td>4.208595</td>\n      <td>-4.599254</td>\n      <td>-1.921424</td>\n      <td>-5.089843</td>\n      <td>2.042049</td>\n      <td>-2.948916</td>\n      <td>...</td>\n      <td>0.337925</td>\n      <td>1.036715</td>\n      <td>0.046358</td>\n      <td>-0.363709</td>\n      <td>0.187713</td>\n      <td>0.154247</td>\n      <td>-0.334710</td>\n      <td>-0.110793</td>\n      <td>0.484499</td>\n      <td>135.718613</td>\n    </tr>\n    <tr>\n      <th>455575</th>\n      <td>76244.183256</td>\n      <td>-4.994159</td>\n      <td>3.467464</td>\n      <td>-6.173283</td>\n      <td>4.212092</td>\n      <td>-4.382754</td>\n      <td>-1.567384</td>\n      <td>-5.102434</td>\n      <td>2.010375</td>\n      <td>-3.026769</td>\n      <td>...</td>\n      <td>0.138840</td>\n      <td>0.980981</td>\n      <td>-0.403597</td>\n      <td>-0.354424</td>\n      <td>0.149215</td>\n      <td>0.149957</td>\n      <td>-0.372540</td>\n      <td>-0.033387</td>\n      <td>0.820844</td>\n      <td>100.721635</td>\n    </tr>\n    <tr>\n      <th>455576</th>\n      <td>76372.773188</td>\n      <td>-5.781734</td>\n      <td>3.486044</td>\n      <td>-6.375878</td>\n      <td>4.272748</td>\n      <td>-4.997231</td>\n      <td>-1.808883</td>\n      <td>-4.950264</td>\n      <td>2.211178</td>\n      <td>-3.472407</td>\n      <td>...</td>\n      <td>0.064922</td>\n      <td>1.168897</td>\n      <td>0.094487</td>\n      <td>-0.849056</td>\n      <td>0.205243</td>\n      <td>0.074032</td>\n      <td>-0.227934</td>\n      <td>-0.071793</td>\n      <td>0.482801</td>\n      <td>254.152225</td>\n    </tr>\n  </tbody>\n</table>\n<p>455577 rows × 30 columns</p>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccf_train_prepared_sm_rectangle_df = pd.DataFrame(data=ccf_train_prepared_sm_rectangle)\n",
    "ccf_train_prepared_sm_rectangle_df.rename(columns={0 : 'Time', 1 : 'V1', 2 : 'V2', 3 : 'V3', 4 : 'V4', 5 : 'V5', 6 : 'V6', 7 : 'V7', 8 : 'V8', 9 : 'V9', 10 : 'V10', 11 : 'V11', 12 : 'V12', 13 : 'V13', 14 : 'V14', 15 : 'V15', 16 : 'V16', 17 : 'V17', 18 : 'V18', 19 : 'V19', 20 : 'V20', 21 : 'V21', 22 : 'V22', 23 : 'V23', 24 : 'V24', 25 : 'V25', 26 : 'V26', 27 : 'V27', 28 : 'V28', 29 : 'Amount' }, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# Anlegen einer Liste von Klassifikatoren.\n",
    "classifier_list_sm_rectangle = create_classifiers()\n",
    "\n",
    "# Trainieren der Klassifikatoren mit den durch SMOTE ausbalancierten Trainingsdaten.\n",
    "train_models(ccf_train_prepared_sm_rectangle_df, ccf_train_labels_sm_rectangle, classifier_list_sm_rectangle)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Klassierung 2.2.1\n",
    "In diesem Abschnitt werden die Daten im Testdatensatz durch die trainierten Algorithmen klassiert."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# Klassierung und Berechnung der Wahrscheinlichkeiten für eine Klassenzuordnung für den Testdatensatz.\n",
    "predictions_sm_rectangle, prediction_probas_sm_rectangle = klassieren(ccf_test_prepared, classifier_list_sm_rectangle)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Auswertung 2.2.1\n",
    "In diesem Abschnitt werden die Klassierungen der Klassifikatoren mit verschiedenen Bewertungskennzahlen und -methoden ausgewertet."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure K-Nearest-Neighbors_Konfusionsmatrix_no_label_22_1\n",
      "Saving figure Decision_Tree_Gini_Konfusionsmatrix_no_label_22_1\n",
      "Saving figure Decision_Tree_Entropy_Konfusionsmatrix_no_label_22_1\n",
      "Saving figure Random_Forest_Gini_Konfusionsmatrix_no_label_22_1\n",
      "Saving figure Random_Forest_Entropy_Konfusionsmatrix_no_label_22_1\n",
      "Saving figure Gaussian_Naive_Bayes_Konfusionsmatrix_no_label_22_1\n",
      "Saving figure K-Nearest-Neighbors_ROC_PR_22_1\n",
      "Saving figure Decision_Tree_Gini_ROC_PR_22_1\n",
      "Saving figure Decision_Tree_Entropy_ROC_PR_22_1\n",
      "Saving figure Random_Forest_Gini_ROC_PR_22_1\n",
      "Saving figure Random_Forest_Entropy_ROC_PR_22_1\n",
      "Saving figure Gaussian_Naive_Bayes_ROC_PR_22_1\n"
     ]
    }
   ],
   "source": [
    "# Auswertung der Klassierungen und berechneten Wahrscheinlichkeiten für eine Klassenzuordnung.\n",
    "auswerten(predictions_sm_rectangle, prediction_probas_sm_rectangle, '22_1')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![K-Nearest-Neighbors_Konfusionsmatrix](images/ccf_project/K-Nearest-Neighbors_Konfusionsmatrix_22_1.png)![Decision_Tree_Gini_Konfusionsmatrix](images/ccf_project/Decision_Tree_Gini_Konfusionsmatrix_22_1.png) ![Decision_Tree_Entropy_Konfusionsmatrix](images/ccf_project/Decision_Tree_Entropy_Konfusionsmatrix_22_1.png)\n",
    "![Random_Forest_Gini_Konfusionsmatrix](images/ccf_project/Random_Forest_Gini_Konfusionsmatrix_22_1.png)![Random_Forest_Entropy_Konfusionsmatrix](images/ccf_project/Random_Forest_Entropy_Konfusionsmatrix_22_1.png)![Gaussian_Naive_Bayes_Konfusionsmatrix](images/ccf_project/Gaussian_Naive_Bayes_Konfusionsmatrix_22_1.png)\n",
    "\n",
    "![K-Nearest-Neighbors_ROC_PR](images/ccf_project/K-Nearest-Neighbors_ROC_PR_22_1.png)\n",
    "![Decision_Tree_Gini_ROC_PR](images/ccf_project/Decision_Tree_Gini_ROC_PR_22_1.png)\n",
    "![Decision_Tree_Entropy_ROC_PR](images/ccf_project/Decision_Tree_Entropy_ROC_PR_22_1.png)\n",
    "![Random_Forest_Gini_ROC_PR](images/ccf_project/Random_Forest_Gini_ROC_PR_22_1.png)\n",
    "![Random_Forest_Entropy_ROC_PR](images/ccf_project/Random_Forest_Entropy_ROC_PR_22_1.png)\n",
    "![Gaussian_Naive_Bayes_ROC_PR](images/ccf_project/Gaussian_Naive_Bayes_ROC_PR_22_1.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Training 2.2.2\n",
    "Die Klassifikatoren werden mit den durch SMOTE (mit der Interpolationsmethode Linie) balancierten Trainingsdaten trainiert."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# Anlegen einer Liste von Klassifikatoren.\n",
    "classifier_list_sm = create_classifiers()\n",
    "\n",
    "# Trainieren der Klassifikatoren mit den durch SMOTE ausbalancierten Trainingsdaten.\n",
    "train_models(ccf_train_prepared_sm, ccf_train_labels_sm, classifier_list_sm)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Klassierung 2.2.2\n",
    "In diesem Abschnitt werden die Daten im Testdatensatz durch die trainierten Algorithmen klassiert."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# Klassierung und Berechnung der Wahrscheinlichkeiten für eine Klassenzuordnung für den Testdatensatz.\n",
    "predictions_sm, prediction_probas_sm = klassieren(ccf_test_prepared, classifier_list_sm)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Auswertung 2.2.2\n",
    "In diesem Abschnitt werden die Klassierungen der Klassifikatoren mit verschiedenen Bewertungskennzahlen und -methoden ausgewertet."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure K-Nearest-Neighbors_Konfusionsmatrix_no_label_22_2\n",
      "Saving figure Decision_Tree_Gini_Konfusionsmatrix_no_label_22_2\n",
      "Saving figure Decision_Tree_Entropy_Konfusionsmatrix_no_label_22_2\n",
      "Saving figure Random_Forest_Gini_Konfusionsmatrix_no_label_22_2\n",
      "Saving figure Random_Forest_Entropy_Konfusionsmatrix_no_label_22_2\n",
      "Saving figure Gaussian_Naive_Bayes_Konfusionsmatrix_no_label_22_2\n",
      "Saving figure K-Nearest-Neighbors_ROC_PR_22_2\n",
      "Saving figure Decision_Tree_Gini_ROC_PR_22_2\n",
      "Saving figure Decision_Tree_Entropy_ROC_PR_22_2\n",
      "Saving figure Random_Forest_Gini_ROC_PR_22_2\n",
      "Saving figure Random_Forest_Entropy_ROC_PR_22_2\n",
      "Saving figure Gaussian_Naive_Bayes_ROC_PR_22_2\n"
     ]
    }
   ],
   "source": [
    "# Auswertung der Klassierungen und berechneten Wahrscheinlichkeiten für eine Klassenzuordnung.\n",
    "auswerten(predictions_sm, prediction_probas_sm, '22_2')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![K-Nearest-Neighbors_Konfusionsmatrix](images/ccf_project/K-Nearest-Neighbors_Konfusionsmatrix_22_2.png)![Decision_Tree_Gini_Konfusionsmatrix](images/ccf_project/Decision_Tree_Gini_Konfusionsmatrix_22_2.png) ![Decision_Tree_Entropy_Konfusionsmatrix](images/ccf_project/Decision_Tree_Entropy_Konfusionsmatrix_22_2.png)\n",
    "![Random_Forest_Gini_Konfusionsmatrix](images/ccf_project/Random_Forest_Gini_Konfusionsmatrix_22_2.png)![Random_Forest_Entropy_Konfusionsmatrix](images/ccf_project/Random_Forest_Entropy_Konfusionsmatrix_22_2.png)![Gaussian_Naive_Bayes_Konfusionsmatrix](images/ccf_project/Gaussian_Naive_Bayes_Konfusionsmatrix_22_2.png)\n",
    "\n",
    "![K-Nearest-Neighbors_ROC_PR](images/ccf_project/K-Nearest-Neighbors_ROC_PR_22_2.png)\n",
    "![Decision_Tree_Gini_ROC_PR](images/ccf_project/Decision_Tree_Gini_ROC_PR_22_2.png)\n",
    "![Decision_Tree_Entropy_ROC_PR](images/ccf_project/Decision_Tree_Entropy_ROC_PR_22_2.png)\n",
    "![Random_Forest_Gini_ROC_PR](images/ccf_project/Random_Forest_Gini_ROC_PR_22_2.png)\n",
    "![Random_Forest_Entropy_ROC_PR](images/ccf_project/Random_Forest_Entropy_ROC_PR_22_2.png)\n",
    "![Gaussian_Naive_Bayes_ROC_PR](images/ccf_project/Gaussian_Naive_Bayes_ROC_PR_22_2.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Training 2.3\n",
    "Die Klassifikatoren werden mit den durch Borderline SMOTE balancierten Trainingsdaten trainiert."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# Anlegen einer Liste von Klassifikatoren.\n",
    "classifier_list_bsm = create_classifiers()\n",
    "\n",
    "# Trainieren der Klassifikatoren mit den durch Borderline SMOTE ausbalancierten Trainingsdaten.\n",
    "train_models(ccf_train_prepared_bsm, ccf_train_labels_bsm, classifier_list_bsm)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Klassierung 2.3\n",
    "In diesem Abschnitt werden die Daten im Testdatensatz durch die trainierten Algorithmen klassiert."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "# Klassierung und Berechnung der Wahrscheinlichkeiten für eine Klassenzuordnung für den Testdatensatz.\n",
    "predictions_bsm, prediction_probas_bsm = klassieren(ccf_test_prepared, classifier_list_bsm)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Auswertung 2.3\n",
    "In diesem Abschnitt werden die Klassierungen der Klassifikatoren mit verschiedenen Bewertungskennzahlen und -methoden ausgewertet."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure K-Nearest-Neighbors_Konfusionsmatrix_no_label_24\n",
      "Saving figure Decision_Tree_Gini_Konfusionsmatrix_no_label_24\n",
      "Saving figure Decision_Tree_Entropy_Konfusionsmatrix_no_label_24\n",
      "Saving figure Random_Forest_Gini_Konfusionsmatrix_no_label_24\n",
      "Saving figure Random_Forest_Entropy_Konfusionsmatrix_no_label_24\n",
      "Saving figure Gaussian_Naive_Bayes_Konfusionsmatrix_no_label_24\n",
      "Saving figure K-Nearest-Neighbors_ROC_PR_24\n",
      "Saving figure Decision_Tree_Gini_ROC_PR_24\n",
      "Saving figure Decision_Tree_Entropy_ROC_PR_24\n",
      "Saving figure Random_Forest_Gini_ROC_PR_24\n",
      "Saving figure Random_Forest_Entropy_ROC_PR_24\n",
      "Saving figure Gaussian_Naive_Bayes_ROC_PR_24\n"
     ]
    }
   ],
   "source": [
    "# Auswertung der Klassierungen und berechneten Wahrscheinlichkeiten für eine Klassenzuordnung.\n",
    "auswerten(predictions_bsm, prediction_probas_bsm, '23')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![K-Nearest-Neighbors_Konfusionsmatrix](images/ccf_project/K-Nearest-Neighbors_Konfusionsmatrix_23.png)![Decision_Tree_Gini_Konfusionsmatrix](images/ccf_project/Decision_Tree_Gini_Konfusionsmatrix_23.png) ![Decision_Tree_Entropy_Konfusionsmatrix](images/ccf_project/Decision_Tree_Entropy_Konfusionsmatrix_23.png)\n",
    "![Random_Forest_Gini_Konfusionsmatrix](images/ccf_project/Random_Forest_Gini_Konfusionsmatrix_23.png)![Random_Forest_Entropy_Konfusionsmatrix](images/ccf_project/Random_Forest_Entropy_Konfusionsmatrix_23.png)![Gaussian_Naive_Bayes_Konfusionsmatrix](images/ccf_project/Gaussian_Naive_Bayes_Konfusionsmatrix_23.png)\n",
    "\n",
    "![K-Nearest-Neighbors_ROC_PR](images/ccf_project/K-Nearest-Neighbors_ROC_PR_23.png)\n",
    "![Decision_Tree_Gini_ROC_PR](images/ccf_project/Decision_Tree_Gini_ROC_PR_23.png)\n",
    "![Decision_Tree_Entropy_ROC_PR](images/ccf_project/Decision_Tree_Entropy_ROC_PR_23.png)\n",
    "![Random_Forest_Gini_ROC_PR](images/ccf_project/Random_Forest_Gini_ROC_PR_23.png)\n",
    "![Random_Forest_Entropy_ROC_PR](images/ccf_project/Random_Forest_Entropy_ROC_PR_23.png)\n",
    "![Gaussian_Naive_Bayes_ROC_PR](images/ccf_project/Gaussian_Naive_Bayes_ROC_PR_23.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Training 2.4\n",
    "Die Klassifikatoren werden mit den durch ADASYN balancierten Trainingsdaten trainiert."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# Anlegen einer Liste von Klassifikatoren.\n",
    "classifier_list_ada = create_classifiers()\n",
    "\n",
    "# Trainieren der Klassifikatoren mit den durch ADASYN ausbalancierten Trainingsdaten.\n",
    "train_models(ccf_train_prepared_ada, ccf_train_labels_ada, classifier_list_ada)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Klassierung 2.4\n",
    "In diesem Abschnitt werden die Daten im Testdatensatz durch die trainierten Algorithmen klassiert."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# Klassierung und Berechnung der Wahrscheinlichkeiten für eine Klassenzuordnung für den Testdatensatz.\n",
    "predictions_ada, prediction_probas_ada = klassieren(ccf_test_prepared, classifier_list_ada)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Auswertung 2.4\n",
    "In diesem Abschnitt werden die Klassierungen der Klassifikatoren mit verschiedenen Bewertungskennzahlen und -methoden ausgewertet."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure K-Nearest-Neighbors_Konfusionsmatrix_no_label_23\n",
      "Saving figure Decision_Tree_Gini_Konfusionsmatrix_no_label_23\n",
      "Saving figure Decision_Tree_Entropy_Konfusionsmatrix_no_label_23\n",
      "Saving figure Random_Forest_Gini_Konfusionsmatrix_no_label_23\n",
      "Saving figure Random_Forest_Entropy_Konfusionsmatrix_no_label_23\n",
      "Saving figure Gaussian_Naive_Bayes_Konfusionsmatrix_no_label_23\n",
      "Saving figure K-Nearest-Neighbors_ROC_PR_23\n",
      "Saving figure Decision_Tree_Gini_ROC_PR_23\n",
      "Saving figure Decision_Tree_Entropy_ROC_PR_23\n",
      "Saving figure Random_Forest_Gini_ROC_PR_23\n",
      "Saving figure Random_Forest_Entropy_ROC_PR_23\n",
      "Saving figure Gaussian_Naive_Bayes_ROC_PR_23\n"
     ]
    }
   ],
   "source": [
    "# Auswertung der Klassierungen und berechneten Wahrscheinlichkeiten für eine Klassenzuordnung.\n",
    "auswerten(predictions_ada, prediction_probas_ada, '24')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![K-Nearest-Neighbors_Konfusionsmatrix](images/ccf_project/K-Nearest-Neighbors_Konfusionsmatrix_24.png)![Decision_Tree_Gini_Konfusionsmatrix](images/ccf_project/Decision_Tree_Gini_Konfusionsmatrix_24.png) ![Decision_Tree_Entropy_Konfusionsmatrix](images/ccf_project/Decision_Tree_Entropy_Konfusionsmatrix_24.png)\n",
    "![Random_Forest_Gini_Konfusionsmatrix](images/ccf_project/Random_Forest_Gini_Konfusionsmatrix_24.png)![Random_Forest_Entropy_Konfusionsmatrix](images/ccf_project/Random_Forest_Entropy_Konfusionsmatrix_24.png)![Gaussian_Naive_Bayes_Konfusionsmatrix](images/ccf_project/Gaussian_Naive_Bayes_Konfusionsmatrix_24.png)\n",
    "\n",
    "![K-Nearest-Neighbors_ROC_PR](images/ccf_project/K-Nearest-Neighbors_ROC_PR_24.png)\n",
    "![Decision_Tree_Gini_ROC_PR](images/ccf_project/Decision_Tree_Gini_ROC_PR_24.png)\n",
    "![Decision_Tree_Entropy_ROC_PR](images/ccf_project/Decision_Tree_Entropy_ROC_PR_24.png)\n",
    "![Random_Forest_Gini_ROC_PR](images/ccf_project/Random_Forest_Gini_ROC_PR_24.png)\n",
    "![Random_Forest_Entropy_ROC_PR](images/ccf_project/Random_Forest_Entropy_ROC_PR_24.png)\n",
    "![Gaussian_Naive_Bayes_ROC_PR](images/ccf_project/Gaussian_Naive_Bayes_ROC_PR_24.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Experimente\n",
    "\n",
    "In diesem Abschnitt werden als Experiment zwei unterschiedliche Kombinationen von Oversampling Algorithmen genutzt, um den Trainingsdatensatz zu balancieren. Anschließend werden jeweils verschiedene Klassifikatoren mit diesen modifizierten Datensätzen trainiert und ausgewertet. Die Abbildungen der Auswertung werden mit der Endung '_3*' abgespeichert. * steht hierbei für die konkrete Oversampling-Methode in der Versuchsreihe."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Datenmodifikation 3.1\n",
    "Als erstes Experiment soll ausgetestet werden, welchen Einfluss ein Training unterschiedlicher Oversampling Algorithmen auf gleich große Teile des ursprünglichen Trainingsdatensatz hat, welche im Anschluss wieder zu einem großen Trainingsdatensatz zusammengesetzt werden."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "# Zweimaliges Aufspalten in insgesamt 4 gleich große Teile\n",
    "\n",
    "# Datensatz halbieren\n",
    "# Der random_state wird auf 42 festgesetzt, damit das Ergebnis reproduzierbar ist.\n",
    "# stratify=ccf_labels sorgt dafür, die Datensätze stratifiziert werden.\n",
    "ccf_train_prepared_0, ccf_train_prepared_1, ccf_train_labels_0, ccf_train_labels_1 = train_test_split(ccf_train_prepared, ccf_train_labels, test_size=0.5, random_state=42, stratify=ccf_train_labels)\n",
    "\n",
    "# Halbe Datensätze halbieren zu Vierteln\n",
    "ccf_train_prepared_0_0, ccf_train_prepared_0_1, ccf_train_labels_0_0, ccf_train_labels_0_1 = train_test_split(ccf_train_prepared_0, ccf_train_labels_0, test_size=0.5, random_state=42, stratify=ccf_train_labels_0)\n",
    "ccf_train_prepared_1_0, ccf_train_prepared_1_1, ccf_train_labels_1_0, ccf_train_labels_1_1 = train_test_split(ccf_train_prepared_1, ccf_train_labels_1, test_size=0.5, random_state=42, stratify=ccf_train_labels_1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Oversampling Algorithmen auf die Datensätze anwenden: _0_0 = ROS; _0_1 = SMOTE; _1_0 = ADASYN; _1_1 = Borderline SMOTE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "ccf_train_prepared_0_0_ros, ccf_train_labels_0_0_ros = ros.fit_resample(ccf_train_prepared_0_0, ccf_train_labels_0_0)\n",
    "\n",
    "ccf_train_prepared_0_1_sm, ccf_train_labels_0_1_sm = sm.fit_resample(ccf_train_prepared_0_1, ccf_train_labels_0_1)\n",
    "\n",
    "ccf_train_prepared_1_0_ada, ccf_train_labels_1_0_ada = ada.fit_resample(ccf_train_prepared_1_0, ccf_train_labels_1_0)\n",
    "\n",
    "ccf_train_prepared_1_1_bsm, ccf_train_labels_1_1_bsm = bsm.fit_resample(ccf_train_prepared_1_1, ccf_train_labels_1_1)\n",
    "\n",
    "# Überführung in ein Dataframe\n",
    "ccf_train_prepared_0_0_ros = pd.DataFrame(ccf_train_prepared_0_0_ros)\n",
    "ccf_train_labels_0_0_ros = pd.DataFrame(ccf_train_labels_0_0_ros)\n",
    "ccf_train_prepared_0_1_sm = pd.DataFrame(ccf_train_prepared_0_1_sm)\n",
    "ccf_train_labels_0_1_sm = pd.DataFrame(ccf_train_labels_0_1_sm)\n",
    "ccf_train_prepared_1_0_ada = pd.DataFrame(ccf_train_prepared_1_0_ada)\n",
    "ccf_train_labels_1_0_ada = pd.DataFrame(ccf_train_labels_1_0_ada)\n",
    "ccf_train_prepared_1_1_bsm = pd.DataFrame(ccf_train_prepared_1_1_bsm)\n",
    "ccf_train_labels_1_1_bsm = pd.DataFrame(ccf_train_labels_1_1_bsm)\n",
    "\n",
    "# Zusammenfügen der Datensätze\n",
    "ccf_train_x1 = pd.concat([ccf_train_prepared_0_0_ros,ccf_train_prepared_0_1_sm, ccf_train_prepared_1_0_ada, ccf_train_prepared_1_1_bsm], axis=0)\n",
    "ccf_train_labels_x1 = pd.concat([ccf_train_labels_0_0_ros,ccf_train_labels_0_1_sm, ccf_train_labels_1_0_ada, ccf_train_labels_1_1_bsm], axis=0)\n",
    "ccf_train_labels_x1 = ccf_train_labels_x1.values.ravel()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Training 3.1\n",
    "Die Klassifikatoren werden mit den Trainingsdaten aus 4 verschiedenen parallelen Oversampling Algorithmen trainiert."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "# Anlegen einer Liste von Klassifikatoren.\n",
    "classifier_list_x1 = create_classifiers()\n",
    "\n",
    "# Trainieren der Klassifikatoren mit den gemäß Experiment 1 abgeänderten Trainingsdaten.\n",
    "train_models(ccf_train_x1, ccf_train_labels_x1, classifier_list_x1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Klassierung 3.1\n",
    "In diesem Abschnitt werden die Daten im Testdatensatz durch die trainierten Algorithmen klassiert."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "# Klassierung und Berechnung der Wahrscheinlichkeiten für eine Klassenzuordnung für den Testdatensatz.\n",
    "predictions_x1, prediction_probas_x1 = klassieren(ccf_test_prepared, classifier_list_x1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Auswertung 3.1\n",
    "In diesem Abschnitt werden die Klassierungen der Klassifikatoren mit verschiedenen Bewertungskennzahlen und -methoden ausgewertet."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure K-Nearest-Neighbors_Konfusionsmatrix_no_label_31\n",
      "Saving figure Decision_Tree_Gini_Konfusionsmatrix_no_label_31\n",
      "Saving figure Decision_Tree_Entropy_Konfusionsmatrix_no_label_31\n",
      "Saving figure Random_Forest_Gini_Konfusionsmatrix_no_label_31\n",
      "Saving figure Random_Forest_Entropy_Konfusionsmatrix_no_label_31\n",
      "Saving figure Gaussian_Naive_Bayes_Konfusionsmatrix_no_label_31\n",
      "Saving figure K-Nearest-Neighbors_ROC_PR_31\n",
      "Saving figure Decision_Tree_Gini_ROC_PR_31\n",
      "Saving figure Decision_Tree_Entropy_ROC_PR_31\n",
      "Saving figure Random_Forest_Gini_ROC_PR_31\n",
      "Saving figure Random_Forest_Entropy_ROC_PR_31\n",
      "Saving figure Gaussian_Naive_Bayes_ROC_PR_31\n"
     ]
    }
   ],
   "source": [
    "# Auswertung der Klassierungen und berechneten Wahrscheinlichkeiten für eine Klassenzuordnung.\n",
    "auswerten(predictions_x1, prediction_probas_x1, '31')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![K-Nearest-Neighbors_Konfusionsmatrix](images/ccf_project/K-Nearest-Neighbors_Konfusionsmatrix_31.png)![Decision_Tree_Gini_Konfusionsmatrix](images/ccf_project/Decision_Tree_Gini_Konfusionsmatrix_31.png) ![Decision_Tree_Entropy_Konfusionsmatrix](images/ccf_project/Decision_Tree_Entropy_Konfusionsmatrix_31.png)\n",
    "![Random_Forest_Gini_Konfusionsmatrix](images/ccf_project/Random_Forest_Gini_Konfusionsmatrix_31.png)![Random_Forest_Entropy_Konfusionsmatrix](images/ccf_project/Random_Forest_Entropy_Konfusionsmatrix_31.png)![Gaussian_Naive_Bayes_Konfusionsmatrix](images/ccf_project/Gaussian_Naive_Bayes_Konfusionsmatrix_31.png)\n",
    "\n",
    "![K-Nearest-Neighbors_ROC_PR](images/ccf_project/K-Nearest-Neighbors_ROC_PR_31.png)\n",
    "![Decision_Tree_Gini_ROC_PR](images/ccf_project/Decision_Tree_Gini_ROC_PR_31.png)\n",
    "![Decision_Tree_Entropy_ROC_PR](images/ccf_project/Decision_Tree_Entropy_ROC_PR_31.png)\n",
    "![Random_Forest_Gini_ROC_PR](images/ccf_project/Random_Forest_Gini_ROC_PR_31.png)\n",
    "![Random_Forest_Entropy_ROC_PR](images/ccf_project/Random_Forest_Entropy_ROC_PR_31.png)\n",
    "![Gaussian_Naive_Bayes_ROC_PR](images/ccf_project/Gaussian_Naive_Bayes_ROC_PR_31.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Datenmodifikation 3.2\n",
    "Als zweites Experiment wird ausgetestet, welchen Einfluss ein geschachteltes Training unterschiedlicher Oversampling Algorithmen auf den Trainingsdatensatz hat. Die Minderheit wird dabei durch jede Oversampling-Methode vergrößert, bis sie gleich groß wie die ursprüngliche Mehrheit ist."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "ada_x2 = ADASYN(random_state=42, n_jobs=-1, sampling_strategy=0.25)\n",
    "bsm_x2 = BorderlineSMOTE(random_state=42, n_jobs=-1, sampling_strategy=0.5)\n",
    "sm_x2 = SMOTE(random_state=42, n_jobs=-1, sampling_strategy=0.75)\n",
    "ros_x2 = RandomOverSampler(random_state=42)\n",
    "\n",
    "# Oversampling durch ADASYN bis Anzahl an Datenpunkten der Minderheit 25% der Anzahl an Datenpunkten der Mehrheit erreicht hat.\n",
    "ccf_train_prepared_ada_x2, ccf_train_labels_ada_x2 = ada_x2.fit_resample(ccf_train_prepared, ccf_train_labels)\n",
    "\n",
    "# Oversampling durch BorderlineSMOTE bis Anzahl an Datenpunkten der Minderheit 50% der Anzahl an Datenpunkten der Mehrheit erreicht hat.\n",
    "ccf_train_prepared_ada_bsm_x2, ccf_train_labels_ada_bsm_x2 = bsm_x2.fit_resample(ccf_train_prepared_ada_x2, ccf_train_labels_ada_x2)\n",
    "\n",
    "# Oversampling durch SMOTE (Linie) bis Anzahl an Datenpunkten der Minderheit 75% der Anzahl an Datenpunkten der Mehrheit erreicht hat.\n",
    "ccf_train_prepared_ada_bsm_sm_x2, ccf_train_labels_ada_bsm_sm_x2 = sm_x2.fit_resample(ccf_train_prepared_ada_bsm_x2, ccf_train_labels_ada_bsm_x2)\n",
    "\n",
    "# Oversampling durch den RandomOverSampler bis Anzahl an Datenpunkten der Minderheit 100% der Anzahl an Datenpunkten der Mehrheit erreicht hat.\n",
    "ccf_train_prepared_ada_bsm_sm_ros_x2, ccf_train_labels_ada_bsm_sm_ros_x2 = ros_x2.fit_resample(ccf_train_prepared_ada_bsm_sm_x2, ccf_train_labels_ada_bsm_sm_x2)\n",
    "\n",
    "ccf_train_x2 = ccf_train_prepared_ada_bsm_sm_ros_x2\n",
    "ccf_train_labels_x2 = ccf_train_labels_ada_bsm_sm_ros_x2\n",
    "ccf_train_labels_x2 = ccf_train_labels_x2.values.ravel()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Training 3.2\n",
    "Die Klassifikatoren werden mit den Trainingsdaten aus 4 ineinander geschachtelten Oversampling Algorithmen trainiert."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "# Anlegen einer Liste von Klassifikatoren.\n",
    "classifier_list_x2 = create_classifiers()\n",
    "\n",
    "# Trainieren der Klassifikatoren mit den gemäß Experiment 1 abgeänderten Trainingsdaten.\n",
    "train_models(ccf_train_x2, ccf_train_labels_x2, classifier_list_x2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Klassierung 3.2\n",
    "In diesem Abschnitt werden die Daten im Testdatensatz `ccf_test_prepared` durch die trainierten Algorithmen klassiert."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "# Klassierung und Berechnung der Wahrscheinlichkeiten für eine Klassenzuordnung für den Testdatensatz.\n",
    "predictions_x2, prediction_probas_x2 = klassieren(ccf_test_prepared, classifier_list_x2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Auswertung 3.2\n",
    "In diesem Abschnitt werden die Klassierungen der Klassifikatoren mit verschiedenen Bewertungskennzahlen und -methoden ausgewertet."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure K-Nearest-Neighbors_Konfusionsmatrix_no_label_32\n",
      "Saving figure Decision_Tree_Gini_Konfusionsmatrix_no_label_32\n",
      "Saving figure Decision_Tree_Entropy_Konfusionsmatrix_no_label_32\n",
      "Saving figure Random_Forest_Gini_Konfusionsmatrix_no_label_32\n",
      "Saving figure Random_Forest_Entropy_Konfusionsmatrix_no_label_32\n",
      "Saving figure Gaussian_Naive_Bayes_Konfusionsmatrix_no_label_32\n",
      "Saving figure K-Nearest-Neighbors_ROC_PR_32\n",
      "Saving figure Decision_Tree_Gini_ROC_PR_32\n",
      "Saving figure Decision_Tree_Entropy_ROC_PR_32\n",
      "Saving figure Random_Forest_Gini_ROC_PR_32\n",
      "Saving figure Random_Forest_Entropy_ROC_PR_32\n",
      "Saving figure Gaussian_Naive_Bayes_ROC_PR_32\n"
     ]
    }
   ],
   "source": [
    "# Auswertung der Klassierungen und berechneten Wahrscheinlichkeiten für eine Klassenzuordnung.\n",
    "auswerten(predictions_x2, prediction_probas_x2, '32')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![K-Nearest-Neighbors_Konfusionsmatrix](images/ccf_project/K-Nearest-Neighbors_Konfusionsmatrix_32.png)![Decision_Tree_Gini_Konfusionsmatrix](images/ccf_project/Decision_Tree_Gini_Konfusionsmatrix_32.png) ![Decision_Tree_Entropy_Konfusionsmatrix](images/ccf_project/Decision_Tree_Entropy_Konfusionsmatrix_32.png)\n",
    "![Random_Forest_Gini_Konfusionsmatrix](images/ccf_project/Random_Forest_Gini_Konfusionsmatrix_32.png)![Random_Forest_Entropy_Konfusionsmatrix](images/ccf_project/Random_Forest_Entropy_Konfusionsmatrix_32.png)![Gaussian_Naive_Bayes_Konfusionsmatrix](images/ccf_project/Gaussian_Naive_Bayes_Konfusionsmatrix_32.png)\n",
    "\n",
    "![K-Nearest-Neighbors_ROC_PR](images/ccf_project/K-Nearest-Neighbors_ROC_PR_32.png)\n",
    "![Decision_Tree_Gini_ROC_PR](images/ccf_project/Decision_Tree_Gini_ROC_PR_32.png)\n",
    "![Decision_Tree_Entropy_ROC_PR](images/ccf_project/Decision_Tree_Entropy_ROC_PR_32.png)\n",
    "![Random_Forest_Gini_ROC_PR](images/ccf_project/Random_Forest_Gini_ROC_PR_32.png)\n",
    "![Random_Forest_Entropy_ROC_PR](images/ccf_project/Random_Forest_Entropy_ROC_PR_32.png)\n",
    "![Gaussian_Naive_Bayes_ROC_PR](images/ccf_project/Gaussian_Naive_Bayes_ROC_PR_32.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}